{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1236\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "from encoder_paths import *\n",
    "import json\n",
    "from pprint import pprint\n",
    "TRAIN_FILE_PATH = \"/tmp/semeval24_task3/SemEval-2024_Task3/official_data/Training_data/text/training.json\"\n",
    "VALIDATION_FILE_PATH = \"/tmp/semeval24_task3/SemEval-2024_Task3/official_data/Training_data/text/testing.json\"\n",
    "with open(TRAIN_FILE_PATH) as f:\n",
    "    train_data = json.load(f)\n",
    "with open(VALIDATION_FILE_PATH) as f:\n",
    "    validation_data = json.load(f)\n",
    "\n",
    "pprint(len(train_data))\n",
    "pprint(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2059, 1024, 1472, 5282, 1647, 369, 326]\n",
      "[0.00048567265662943174, 0.0009765625, 0.0006793478260869565, 0.0001893222264293828, 0.0006071645415907711, 0.0027100271002710027, 0.003067484662576687]\n"
     ]
    }
   ],
   "source": [
    "class EmotionIndexer:\n",
    "    def __init__(self):\n",
    "        self.emotion_to_index = {\n",
    "            'joy': 0,\n",
    "            'sadness': 1,\n",
    "            'anger': 2,\n",
    "            'neutral': 3,\n",
    "            'surprise': 4,\n",
    "            'disgust': 5,\n",
    "            'fear': 6,\n",
    "            'pad': 7,\n",
    "        }\n",
    "        self.emotion_freq = [0]*7\n",
    "        self.weights = None\n",
    "\n",
    "        self.index_to_emotion = {index: emotion for emotion, index in self.emotion_to_index.items()}\n",
    "\n",
    "    def emotion_to_idx(self, emotion):\n",
    "        return self.emotion_to_index.get(emotion, None)\n",
    "\n",
    "    def idx_to_emotion(self, index):\n",
    "        return self.index_to_emotion.get(index, None)\n",
    "    \n",
    "    def compute_weights(self, data):\n",
    "        for conversation in data:\n",
    "            conversation = conversation['conversation']\n",
    "            for utterance in conversation:\n",
    "                emotion = utterance['emotion']\n",
    "                self.emotion_freq[self.emotion_to_index[emotion]] += 1\n",
    "        print(self.emotion_freq)\n",
    "        self.weights = [1/freq for freq in self.emotion_freq]\n",
    "\n",
    "# Example usage\n",
    "indexer = EmotionIndexer()\n",
    "indexer.compute_weights(train_data)\n",
    "print(indexer.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sadness', 'fear', 'disgust', 'surprise', 'anger', 'neutral', 'joy'}\n"
     ]
    }
   ],
   "source": [
    "all_emotions = set()\n",
    "for conversation in train_data:\n",
    "    conversation = conversation[\"conversation\"]\n",
    "    for utterance in conversation:\n",
    "        all_emotions.add(utterance[\"emotion\"])\n",
    "pprint(all_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/suyash.mathur/anaconda3/envs/mindeye/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_video\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# video_id_mapping = np.load(\"/home2/akshett.jindal/research/semeval24/task3/MECPE/data/video_id_mapping.npy\", allow_pickle=True)\n",
    "# print(video_id_mapping)\n",
    "# video_id_mapping = video_id_mapping.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "class YourAudioEncoder():\n",
    "    def __init__(self, audio_embeddings_path):\n",
    "        with open(audio_embeddings_path, \"rb\") as f:\n",
    "            self.audio_embeddings = pickle.load(f)\n",
    "\n",
    "    def lmao(self, audio_name):\n",
    "        audio_name = audio_name.split(\".\")[0]\n",
    "        audio_embedding = self.audio_embeddings[audio_name]\n",
    "        audio_embedding = audio_embedding.squeeze()\n",
    "        return torch.from_numpy(audio_embedding)\n",
    "    \n",
    "class YourVideoEncoder():\n",
    "    def __init__(self, video_embeddings_path):\n",
    "        with open(video_embeddings_path, \"rb\") as f:\n",
    "            self.video_embeddings = pickle.load(f)\n",
    "\n",
    "    def lmao(self, video_name):\n",
    "        # video_name = video_name.split(\".\")[0]\n",
    "        video_embedding = self.video_embeddings[video_name].reshape((16,-1))\n",
    "        video_embedding = np.mean(video_embedding, axis=0)\n",
    "        return torch.from_numpy(video_embedding)\n",
    "\n",
    "class YourTextEncoder():\n",
    "    def __init__(self, text_embeddings_path):\n",
    "        with open(text_embeddings_path, \"rb\") as f:\n",
    "            self.text_embeddings = pickle.load(f)\n",
    "\n",
    "    def lmao(self, video_name):\n",
    "        text_embedding = self.text_embeddings[video_name]\n",
    "        return torch.from_numpy(text_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, json_file, audio_encoder, video_encoder, text_encoder, max_seq_len):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.data = self.load_data(json_file)\n",
    "        self.audio_encoder = audio_encoder\n",
    "        self.video_encoder = video_encoder\n",
    "        self.text_encoder = text_encoder\n",
    "\n",
    "    def load_data(self, json_file):\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        conversation = self.data[idx]['conversation']\n",
    "        emotion_labels = [utterance['emotion'] for utterance in conversation]\n",
    "        audio_paths = [utterance['video_name'].replace('mp4', 'wav') for utterance in conversation]\n",
    "        video_paths = [utterance['video_name'] for utterance in conversation]\n",
    "        texts = [utterance['video_name'] for utterance in conversation]\n",
    "\n",
    "        audio_embeddings = [self.audio_encoder.lmao(audio_path) for audio_path in audio_paths]\n",
    "        video_embeddings = [self.video_encoder.lmao(video_path) for video_path in video_paths]\n",
    "        text_embeddings = [self.text_encoder.lmao(text) for text in texts]\n",
    "\n",
    "        # Pad or truncate conversations to the maximum sequence length\n",
    "        if len(conversation) < self.max_seq_len:\n",
    "            pad_length = self.max_seq_len - len(conversation)\n",
    "            audio_embeddings += [torch.zeros_like(audio_embeddings[0])] * pad_length\n",
    "            video_embeddings += [torch.zeros_like(video_embeddings[0])] * pad_length\n",
    "            text_embeddings += [torch.zeros_like(text_embeddings[0])] * pad_length\n",
    "            emotion_labels += ['pad'] * pad_length\n",
    "            pad_mask = [1] * len(conversation) + [0] * pad_length\n",
    "        else:\n",
    "            audio_embeddings = audio_embeddings[:self.max_seq_len]\n",
    "            video_embeddings = video_embeddings[:self.max_seq_len]\n",
    "            text_embeddings = text_embeddings[:self.max_seq_len]\n",
    "            emotion_labels = emotion_labels[:self.max_seq_len]\n",
    "            pad_mask = [1] * self.max_seq_len\n",
    "\n",
    "        emotion_indices = [indexer.emotion_to_idx(emotion) for emotion in emotion_labels]\n",
    "        \n",
    "        audio_embeddings = torch.stack(audio_embeddings)\n",
    "        video_embeddings = torch.stack(video_embeddings)\n",
    "        text_embeddings = torch.stack(text_embeddings)\n",
    "        emotion_indices = torch.from_numpy(np.array(emotion_indices))\n",
    "        pad_mask = torch.from_numpy(np.array(pad_mask))\n",
    "        \n",
    "        return {\n",
    "            'audio': audio_embeddings,\n",
    "            'video': video_embeddings,\n",
    "            'text': text_embeddings,\n",
    "            'emotion_labels': emotion_indices,\n",
    "            'pad_mask': pad_mask,\n",
    "        }\n",
    "# Example usage\n",
    "# You need to define your audio, video, and text encoders accordingly\n",
    "\n",
    "# Define your data paths\n",
    "# DATA_DIR = \"/tmp/semeval24_task3\"\n",
    "\n",
    "# AUDIO_EMBEDDINGS_FILEPATH = \"/tmp/semeval24_task3/og_paper_embeddings/audio_embedding_6373.npy\"\n",
    "# VIDEO_EMBEDDINGS_FILEPATH = \"/tmp/semeval24_task3/og_paper_embeddings/video_embedding_4096.npy\"\n",
    "# TEXT_EMBEDDINGS_FILEPATH = os.path.join(DATA_DIR, \"text_embeddings\", \"text_embeddings_bert_base.pkl\")\n",
    "\n",
    "audio_encoder = YourAudioEncoder(AUDIO_EMBEDDINGS_FILEPATH)\n",
    "video_encoder = YourVideoEncoder(VIDEO_EMBEDDINGS_FILEPATH)\n",
    "text_encoder = YourTextEncoder(TEXT_EMBEDDINGS_FILEPATH)\n",
    "max_seq_len = 40  # Adjust this according to your needs\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "train_dataset = ConversationDataset(TRAIN_FILE_PATH, audio_encoder, video_encoder, text_encoder, max_seq_len)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "validation_dataset = ConversationDataset(VALIDATION_FILE_PATH, audio_encoder, video_encoder, text_encoder, max_seq_len)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Example of iterating through batches\n",
    "# for batch in dataloader:\n",
    "#     audio = batch['audio']  # Shape: (batch_size, max_seq_len, audio_embedding_size)\n",
    "#     video = batch['video']  # Shape: (batch_size, max_seq_len, video_embedding_size)\n",
    "#     text = batch['text']    # Shape: (batch_size, max_seq_len, text_embedding_size)\n",
    "#     emotions = batch['emotion_labels']  # List of emotion labels for each utterance in the batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# class EmotionClassifier(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, num_heads, dropout, num_emotions):\n",
    "#         super(EmotionClassifier, self).__init__()\n",
    "        \n",
    "#         self.first_linear = nn.Linear(input_size, hidden_size, dtype=torch.float32)\n",
    "\n",
    "#         self.transformer_encoder = TransformerEncoder(\n",
    "#             TransformerEncoderLayer(hidden_size, num_heads, hidden_size, dropout),\n",
    "#             num_layers\n",
    "#         )\n",
    "        \n",
    "#         self.linear = nn.Linear(hidden_size, num_emotions)\n",
    "\n",
    "#     def forward(self, audio_encoding, video_encoding, text_encoding):\n",
    "\n",
    "#         # Concatenate or combine the audio, video, and text encodings here\n",
    "#         # You can use any method like concatenation, addition, or other fusion techniques\n",
    "#         # Combine the encodings (you can customize this part)\n",
    "#         audio_encoding = audio_encoding.float()\n",
    "#         video_encoding = video_encoding.float()\n",
    "#         text_encoding = text_encoding.float().squeeze()\n",
    "#         combined_encoding = torch.cat((audio_encoding, video_encoding, text_encoding), dim=2)\n",
    "        \n",
    "#         combined_encoding = self.first_linear(combined_encoding)\n",
    "        \n",
    "        \n",
    "#         combined_encoding = combined_encoding.permute(1, 0, 2)  # Transformer expects (seq_len, batch_size, input_size)\n",
    "        \n",
    "        \n",
    "#         transformer_output = self.transformer_encoder(combined_encoding)\n",
    "\n",
    "#         # Take the output of the Transformer encoder for the last position as the summary\n",
    "#         emotion_logits = self.linear(transformer_output.permute(1, 0, 2))\n",
    "#         # Apply a softmax layer\n",
    "#         emotion_logits = torch.softmax(emotion_logits, dim=2)\n",
    "\n",
    "#         return emotion_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_emotions, embedding_dropout=0.2):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        \n",
    "        # Dropouts for each modality\n",
    "        self.audio_dropout = nn.Dropout(embedding_dropout)\n",
    "        self.video_dropout = nn.Dropout(embedding_dropout)\n",
    "        self.text_dropout = nn.Dropout(embedding_dropout)\n",
    "\n",
    "        # Initial linear layer to process concatenated embeddings\n",
    "        self.first_linear = nn.Linear(input_size, hidden_size, dtype=torch.float32)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Additional linear layer for further processing\n",
    "        self.second_linear_layer = nn.Linear(hidden_size, hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # Final linear layer to predict emotion categories\n",
    "        self.final_linear = nn.Linear(hidden_size, num_emotions, dtype=torch.float32)\n",
    "\n",
    "    def forward(self, audio_encoding, video_encoding, text_encoding):\n",
    "        # Concatenate or combine the audio, video, and text encodings\n",
    "        audio_encoding = self.audio_dropout(audio_encoding.float())\n",
    "        video_encoding = self.video_dropout(video_encoding.float())\n",
    "        text_encoding = self.text_dropout(text_encoding.float().squeeze())\n",
    "        \n",
    "        combined_encoding = torch.cat((audio_encoding, video_encoding, text_encoding), dim=2)\n",
    "        \n",
    "        # Pass the combined encoding through linear layers and activation\n",
    "        combined_encoding = self.first_linear(combined_encoding)\n",
    "        combined_encoding = self.relu(combined_encoding)\n",
    "        combined_encoding = self.second_linear_layer(combined_encoding)\n",
    "        combined_encoding = self.relu(combined_encoding) # Apply ReLU before final layer\n",
    "        \n",
    "        # Final linear layer to produce emotion logits\n",
    "        emotion_logits = self.final_linear(combined_encoding)\n",
    "        \n",
    "        # Apply a softmax layer to get probabilities (if necessary depending on your loss function)\n",
    "        emotion_probs = torch.softmax(emotion_logits, dim=2)\n",
    "\n",
    "        return emotion_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Sequence\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\" Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n",
    "\n",
    "    It is essentially an enhancement to cross entropy loss and is\n",
    "    useful for classification tasks when there is a large class imbalance.\n",
    "    x is expected to contain raw, unnormalized scores for each class.\n",
    "    y is expected to contain class labels.\n",
    "\n",
    "    Shape:\n",
    "        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n",
    "        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 alpha: Optional[Tensor] = None,\n",
    "                 gamma: float = 0.,\n",
    "                 reduction: str = 'mean',\n",
    "                 ignore_index: int = -100):\n",
    "        \"\"\"Constructor.\n",
    "\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class. Defaults to None.\n",
    "            gamma (float, optional): A constant, as described in the paper.\n",
    "                Defaults to 0.\n",
    "            reduction (str, optional): 'mean', 'sum' or 'none'.\n",
    "                Defaults to 'mean'.\n",
    "            ignore_index (int, optional): class label to ignore.\n",
    "                Defaults to -100.\n",
    "        \"\"\"\n",
    "        if reduction not in ('mean', 'sum', 'none'):\n",
    "            raise ValueError(\n",
    "                'Reduction must be one of: \"mean\", \"sum\", \"none\".')\n",
    "\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.nll_loss = nn.NLLLoss(\n",
    "            weight=alpha, reduction='none', ignore_index=ignore_index)\n",
    "\n",
    "    def __repr__(self):\n",
    "        arg_keys = ['alpha', 'gamma', 'ignore_index', 'reduction']\n",
    "        arg_vals = [self.__dict__[k] for k in arg_keys]\n",
    "        arg_strs = [f'{k}={v!r}' for k, v in zip(arg_keys, arg_vals)]\n",
    "        arg_str = ', '.join(arg_strs)\n",
    "        return f'{type(self).__name__}({arg_str})'\n",
    "\n",
    "    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n",
    "        if x.ndim > 2:\n",
    "            # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n",
    "            c = x.shape[1]\n",
    "            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n",
    "            # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n",
    "            y = y.view(-1)\n",
    "\n",
    "        unignored_mask = y != self.ignore_index\n",
    "        y = y[unignored_mask]\n",
    "        if len(y) == 0:\n",
    "            return torch.tensor(0.)\n",
    "        x = x[unignored_mask]\n",
    "\n",
    "        # compute weighted cross entropy term: -alpha * log(pt)\n",
    "        # (alpha is already part of self.nll_loss)\n",
    "        log_p = F.log_softmax(x, dim=-1)\n",
    "        ce = self.nll_loss(log_p, y)\n",
    "\n",
    "        # get true class column from each row\n",
    "        all_rows = torch.arange(len(x))\n",
    "        log_pt = log_p[all_rows, y]\n",
    "\n",
    "        # compute focal term: (1 - pt)^gamma\n",
    "        pt = log_pt.exp()\n",
    "        focal_term = (1 - pt)**self.gamma\n",
    "\n",
    "        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n",
    "        loss = focal_term * ce\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "# def focal_loss(alpha: Optional[Sequence] = None,\n",
    "#                gamma: float = 0.,\n",
    "#                reduction: str = 'mean',\n",
    "#                ignore_index: int = -100,\n",
    "#                device='cpu',\n",
    "#                dtype=torch.float32) -> FocalLoss:\n",
    "#     \"\"\"Factory function for FocalLoss.\n",
    "\n",
    "#     Args:\n",
    "#         alpha (Sequence, optional): Weights for each class. Will be converted\n",
    "#             to a Tensor if not None. Defaults to None.\n",
    "#         gamma (float, optional): A constant, as described in the paper.\n",
    "#             Defaults to 0.\n",
    "#         reduction (str, optional): 'mean', 'sum' or 'none'.\n",
    "#             Defaults to 'mean'.\n",
    "#         ignore_index (int, optional): class label to ignore.\n",
    "#             Defaults to -100.\n",
    "#         device (str, optional): Device to move alpha to. Defaults to 'cpu'.\n",
    "#         dtype (torch.dtype, optional): dtype to cast alpha to.\n",
    "#             Defaults to torch.float32.\n",
    "\n",
    "#     Returns:\n",
    "#         A FocalLoss object\n",
    "#     \"\"\"\n",
    "#     if alpha is not None:\n",
    "#         if not isinstance(alpha, Tensor):\n",
    "#             alpha = torch.tensor(alpha)\n",
    "#         alpha = alpha.to(device=device, dtype=dtype)\n",
    "\n",
    "#     fl = FocalLoss(\n",
    "#         alpha=alpha,\n",
    "#         gamma=gamma,\n",
    "#         reduction=reduction,\n",
    "#         ignore_index=ignore_index)\n",
    "#     return fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Focal Loss\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, gamma=2.0, reduction='mean'):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.gamma = gamma\n",
    "#         self.reduction = reduction\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "#         # Calculate Cross-Entropy Loss, but do not reduce (keep the same shape as input)\n",
    "#         ce_loss = F.cross_entropy(input, target, reduction='none') \n",
    "#         pt = torch.exp(-ce_loss)  # Calculate p_t\n",
    "#         focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()  # Calculate Focal Loss\n",
    "\n",
    "#         if self.reduction == 'mean':\n",
    "#             return focal_loss.mean()\n",
    "#         elif self.reduction == 'sum':\n",
    "#             return focal_loss.sum()\n",
    "#         else:\n",
    "#             return focal_loss\n",
    "\n",
    "# # Replace the loss function with Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2059, 1024, 1472, 5282, 1647, 369, 326]\n"
     ]
    }
   ],
   "source": [
    "print(indexer.emotion_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joy': 0, 'sadness': 1, 'anger': 2, 'neutral': 3, 'surprise': 4, 'disgust': 5, 'fear': 6, 'pad': 7}\n"
     ]
    }
   ],
   "source": [
    "print(indexer.emotion_to_index)\n",
    "# 1 1 1 0.25 1 3 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/semeval24_task3/text_embeddings/text_embeddings_roberta_base_emotion.pkl\n",
      "/tmp/semeval24_task3/audio_embeddings/audio_embeddings_facebook_wav2vec2-large-960h.pkl\n",
      "/tmp/semeval24_task3/video_embeddings/final_embeddings.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:07<00:00, 10.52it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60] Training Loss: 0.011704922779527083\n",
      "Epoch [1/60] Validation Loss: 0.0111644656293922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.52       242\n",
      "           1       0.22      0.71      0.34       123\n",
      "           2       0.64      0.06      0.11       143\n",
      "           3       0.70      0.48      0.57       647\n",
      "           4       0.41      0.64      0.50       193\n",
      "           5       0.19      0.07      0.10        45\n",
      "           6       0.11      0.04      0.06        47\n",
      "\n",
      "    accuracy                           0.46      1440\n",
      "   macro avg       0.40      0.36      0.31      1440\n",
      "weighted avg       0.55      0.46      0.46      1440\n",
      "\n",
      "Epoch [1/60] Accuracy: 0.4190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:07<00:00, 10.44it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/60] Training Loss: 0.011243263061473949\n",
      "Epoch [2/60] Validation Loss: 0.010968064433998531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.56      0.52       242\n",
      "           1       0.37      0.50      0.42       123\n",
      "           2       0.33      0.09      0.14       143\n",
      "           3       0.75      0.33      0.46       647\n",
      "           4       0.39      0.70      0.50       193\n",
      "           5       0.09      0.47      0.15        45\n",
      "           6       0.08      0.17      0.11        47\n",
      "\n",
      "    accuracy                           0.41      1440\n",
      "   macro avg       0.36      0.40      0.33      1440\n",
      "weighted avg       0.54      0.41      0.42      1440\n",
      "\n",
      "Epoch [2/60] Accuracy: 0.4639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:07<00:00, 10.87it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/60] Training Loss: 0.01112124329473068\n",
      "Epoch [3/60] Validation Loss: 0.010886109785901175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.61      0.53       242\n",
      "           1       0.53      0.37      0.44       123\n",
      "           2       0.60      0.02      0.04       143\n",
      "           3       0.73      0.46      0.56       647\n",
      "           4       0.47      0.63      0.54       193\n",
      "           5       0.09      0.44      0.15        45\n",
      "           6       0.10      0.32      0.15        47\n",
      "\n",
      "    accuracy                           0.45      1440\n",
      "   macro avg       0.43      0.41      0.35      1440\n",
      "weighted avg       0.58      0.45      0.47      1440\n",
      "\n",
      "Epoch [3/60] Accuracy: 0.4522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:07<00:00, 10.79it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/60] Training Loss: 0.011005147972251014\n",
      "Epoch [4/60] Validation Loss: 0.010893838935428196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.50      0.54       242\n",
      "           1       0.26      0.63      0.37       123\n",
      "           2       0.27      0.16      0.20       143\n",
      "           3       0.73      0.44      0.55       647\n",
      "           4       0.45      0.66      0.53       193\n",
      "           5       0.12      0.27      0.16        45\n",
      "           6       0.10      0.15      0.12        47\n",
      "\n",
      "    accuracy                           0.45      1440\n",
      "   macro avg       0.36      0.40      0.35      1440\n",
      "weighted avg       0.54      0.45      0.47      1440\n",
      "\n",
      "Epoch [4/60] Accuracy: 0.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:07<00:00, 10.44it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/60] Training Loss: 0.010891706086661547\n",
      "Epoch [5/60] Validation Loss: 0.010966948254240884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.53      0.55       242\n",
      "           1       0.38      0.48      0.42       123\n",
      "           2       0.26      0.14      0.18       143\n",
      "           3       0.77      0.27      0.40       647\n",
      "           4       0.40      0.69      0.51       193\n",
      "           5       0.08      0.62      0.15        45\n",
      "           6       0.10      0.17      0.13        47\n",
      "\n",
      "    accuracy                           0.38      1440\n",
      "   macro avg       0.36      0.42      0.33      1440\n",
      "weighted avg       0.56      0.38      0.40      1440\n",
      "\n",
      "Epoch [5/60] Accuracy: 0.4935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:07<00:00,  9.86it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/60] Training Loss: 0.01081765301954434\n",
      "Epoch [6/60] Validation Loss: 0.01091937671105067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.58      0.55       242\n",
      "           1       0.35      0.54      0.43       123\n",
      "           2       0.24      0.43      0.31       143\n",
      "           3       0.74      0.39      0.51       647\n",
      "           4       0.47      0.64      0.54       193\n",
      "           5       0.12      0.27      0.16        45\n",
      "           6       0.19      0.09      0.12        47\n",
      "\n",
      "    accuracy                           0.46      1440\n",
      "   macro avg       0.38      0.42      0.37      1440\n",
      "weighted avg       0.55      0.46      0.47      1440\n",
      "\n",
      "Epoch [6/60] Accuracy: 0.4922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:03<00:00, 21.67it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 84.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/60] Training Loss: 0.010723128157478707\n",
      "Epoch [7/60] Validation Loss: 0.0107732897831334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.63      0.54       242\n",
      "           1       0.41      0.47      0.44       123\n",
      "           2       0.37      0.15      0.21       143\n",
      "           3       0.75      0.43      0.55       647\n",
      "           4       0.44      0.67      0.53       193\n",
      "           5       0.13      0.36      0.19        45\n",
      "           6       0.11      0.28      0.15        47\n",
      "\n",
      "    accuracy                           0.47      1440\n",
      "   macro avg       0.38      0.43      0.37      1440\n",
      "weighted avg       0.55      0.47      0.48      1440\n",
      "\n",
      "Epoch [7/60] Accuracy: 0.5012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 63.17it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 84.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/60] Training Loss: 0.010647008636136959\n",
      "Epoch [8/60] Validation Loss: 0.010839909315109253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.49      0.53       242\n",
      "           1       0.36      0.54      0.43       123\n",
      "           2       0.33      0.20      0.25       143\n",
      "           3       0.72      0.48      0.58       647\n",
      "           4       0.44      0.67      0.53       193\n",
      "           5       0.09      0.31      0.14        45\n",
      "           6       0.12      0.21      0.16        47\n",
      "\n",
      "    accuracy                           0.47      1440\n",
      "   macro avg       0.38      0.42      0.37      1440\n",
      "weighted avg       0.55      0.47      0.49      1440\n",
      "\n",
      "Epoch [8/60] Accuracy: 0.5042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 62.10it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 85.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/60] Training Loss: 0.010592137027896775\n",
      "Epoch [9/60] Validation Loss: 0.010795322805643081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.62      0.53       242\n",
      "           1       0.46      0.39      0.42       123\n",
      "           2       0.35      0.27      0.30       143\n",
      "           3       0.73      0.50      0.59       647\n",
      "           4       0.52      0.60      0.56       193\n",
      "           5       0.14      0.31      0.20        45\n",
      "           6       0.10      0.28      0.15        47\n",
      "\n",
      "    accuracy                           0.49      1440\n",
      "   macro avg       0.39      0.42      0.39      1440\n",
      "weighted avg       0.55      0.49      0.51      1440\n",
      "\n",
      "Epoch [9/60] Accuracy: 0.5180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 58.75it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 83.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/60] Training Loss: 0.01048761578320341\n",
      "Epoch [10/60] Validation Loss: 0.01079725796977679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.55       242\n",
      "           1       0.42      0.43      0.43       123\n",
      "           2       0.29      0.36      0.32       143\n",
      "           3       0.74      0.51      0.60       647\n",
      "           4       0.49      0.62      0.54       193\n",
      "           5       0.17      0.27      0.21        45\n",
      "           6       0.11      0.21      0.15        47\n",
      "\n",
      "    accuracy                           0.50      1440\n",
      "   macro avg       0.39      0.43      0.40      1440\n",
      "weighted avg       0.55      0.50      0.51      1440\n",
      "\n",
      "Epoch [10/60] Accuracy: 0.5202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 63.41it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 70.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/60] Training Loss: 0.010450855500690847\n",
      "Epoch [11/60] Validation Loss: 0.010871782567765978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.57      0.55       242\n",
      "           1       0.37      0.54      0.44       123\n",
      "           2       0.28      0.42      0.34       143\n",
      "           3       0.76      0.39      0.52       647\n",
      "           4       0.46      0.69      0.55       193\n",
      "           5       0.11      0.27      0.16        45\n",
      "           6       0.17      0.19      0.18        47\n",
      "\n",
      "    accuracy                           0.47      1440\n",
      "   macro avg       0.38      0.44      0.39      1440\n",
      "weighted avg       0.56      0.47      0.48      1440\n",
      "\n",
      "Epoch [11/60] Accuracy: 0.5347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 59.98it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 82.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/60] Training Loss: 0.010374227761537123\n",
      "Epoch [12/60] Validation Loss: 0.010830735332436031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54       242\n",
      "           1       0.38      0.46      0.41       123\n",
      "           2       0.28      0.27      0.27       143\n",
      "           3       0.72      0.52      0.61       647\n",
      "           4       0.51      0.59      0.55       193\n",
      "           5       0.12      0.40      0.19        45\n",
      "           6       0.13      0.23      0.17        47\n",
      "\n",
      "    accuracy                           0.49      1440\n",
      "   macro avg       0.38      0.43      0.39      1440\n",
      "weighted avg       0.55      0.49      0.51      1440\n",
      "\n",
      "Epoch [12/60] Accuracy: 0.5415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 60.03it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 81.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/60] Training Loss: 0.010330924925932166\n",
      "Epoch [13/60] Validation Loss: 0.010897177126672533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.65      0.54       242\n",
      "           1       0.33      0.56      0.42       123\n",
      "           2       0.33      0.22      0.27       143\n",
      "           3       0.77      0.34      0.47       647\n",
      "           4       0.45      0.67      0.54       193\n",
      "           5       0.09      0.29      0.14        45\n",
      "           6       0.15      0.26      0.19        47\n",
      "\n",
      "    accuracy                           0.44      1440\n",
      "   macro avg       0.37      0.43      0.36      1440\n",
      "weighted avg       0.55      0.44      0.45      1440\n",
      "\n",
      "Epoch [13/60] Accuracy: 0.5495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 61.42it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 82.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/60] Training Loss: 0.010278653585614217\n",
      "Epoch [14/60] Validation Loss: 0.01085526305768225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.57      0.54       242\n",
      "           1       0.43      0.46      0.44       123\n",
      "           2       0.31      0.31      0.31       143\n",
      "           3       0.71      0.52      0.60       647\n",
      "           4       0.46      0.65      0.54       193\n",
      "           5       0.12      0.29      0.17        45\n",
      "           6       0.23      0.17      0.20        47\n",
      "\n",
      "    accuracy                           0.50      1440\n",
      "   macro avg       0.39      0.42      0.40      1440\n",
      "weighted avg       0.54      0.50      0.51      1440\n",
      "\n",
      "Epoch [14/60] Accuracy: 0.5477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 61.03it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 79.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/60] Training Loss: 0.01017799297374735\n",
      "Epoch [15/60] Validation Loss: 0.010811953163809247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.53       242\n",
      "           1       0.38      0.46      0.42       123\n",
      "           2       0.27      0.37      0.31       143\n",
      "           3       0.73      0.52      0.61       647\n",
      "           4       0.49      0.65      0.56       193\n",
      "           5       0.16      0.24      0.19        45\n",
      "           6       0.17      0.21      0.19        47\n",
      "\n",
      "    accuracy                           0.50      1440\n",
      "   macro avg       0.39      0.43      0.40      1440\n",
      "weighted avg       0.55      0.50      0.52      1440\n",
      "\n",
      "Epoch [15/60] Accuracy: 0.5588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 63.53it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 83.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/60] Training Loss: 0.010105925442618645\n",
      "Epoch [16/60] Validation Loss: 0.010797774460580613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.64      0.57       242\n",
      "           1       0.37      0.48      0.42       123\n",
      "           2       0.33      0.41      0.36       143\n",
      "           3       0.73      0.44      0.55       647\n",
      "           4       0.48      0.66      0.55       193\n",
      "           5       0.12      0.31      0.18        45\n",
      "           6       0.17      0.15      0.16        47\n",
      "\n",
      "    accuracy                           0.49      1440\n",
      "   macro avg       0.39      0.44      0.40      1440\n",
      "weighted avg       0.55      0.49      0.50      1440\n",
      "\n",
      "Epoch [16/60] Accuracy: 0.5781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 64.48it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 83.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/60] Training Loss: 0.010058414291029778\n",
      "Epoch [17/60] Validation Loss: 0.010880330287747913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.57      0.55       242\n",
      "           1       0.35      0.43      0.39       123\n",
      "           2       0.25      0.40      0.31       143\n",
      "           3       0.76      0.40      0.52       647\n",
      "           4       0.41      0.73      0.53       193\n",
      "           5       0.13      0.18      0.15        45\n",
      "           6       0.14      0.19      0.16        47\n",
      "\n",
      "    accuracy                           0.46      1440\n",
      "   macro avg       0.37      0.41      0.37      1440\n",
      "weighted avg       0.55      0.46      0.47      1440\n",
      "\n",
      "Epoch [17/60] Accuracy: 0.5817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 62.99it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 72.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/60] Training Loss: 0.010041814610351042\n",
      "Epoch [18/60] Validation Loss: 0.010789621455801857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.51      0.54       242\n",
      "           1       0.40      0.40      0.40       123\n",
      "           2       0.31      0.34      0.32       143\n",
      "           3       0.74      0.53      0.61       647\n",
      "           4       0.48      0.66      0.56       193\n",
      "           5       0.14      0.29      0.18        45\n",
      "           6       0.12      0.30      0.17        47\n",
      "\n",
      "    accuracy                           0.50      1440\n",
      "   macro avg       0.39      0.43      0.40      1440\n",
      "weighted avg       0.56      0.50      0.52      1440\n",
      "\n",
      "Epoch [18/60] Accuracy: 0.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 57.38it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 84.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/60] Training Loss: 0.00990995750784316\n",
      "Epoch [19/60] Validation Loss: 0.010953751785887613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.52      0.54       242\n",
      "           1       0.32      0.56      0.41       123\n",
      "           2       0.29      0.24      0.26       143\n",
      "           3       0.73      0.48      0.58       647\n",
      "           4       0.41      0.71      0.52       193\n",
      "           5       0.12      0.20      0.15        45\n",
      "           6       0.23      0.23      0.23        47\n",
      "\n",
      "    accuracy                           0.48      1440\n",
      "   macro avg       0.38      0.42      0.39      1440\n",
      "weighted avg       0.55      0.48      0.50      1440\n",
      "\n",
      "Epoch [19/60] Accuracy: 0.6014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 65.45it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 85.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/60] Training Loss: 0.009931668026203181\n",
      "Epoch [20/60] Validation Loss: 0.010904121067788866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.56       242\n",
      "           1       0.35      0.43      0.39       123\n",
      "           2       0.22      0.41      0.29       143\n",
      "           3       0.76      0.35      0.48       647\n",
      "           4       0.44      0.70      0.54       193\n",
      "           5       0.12      0.27      0.17        45\n",
      "           6       0.15      0.17      0.16        47\n",
      "\n",
      "    accuracy                           0.44      1440\n",
      "   macro avg       0.37      0.42      0.37      1440\n",
      "weighted avg       0.55      0.44      0.45      1440\n",
      "\n",
      "Epoch [20/60] Accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 60.09it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 79.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/60] Training Loss: 0.009814579955305467\n",
      "Epoch [21/60] Validation Loss: 0.01087118246489101\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.59      0.55       242\n",
      "           1       0.33      0.50      0.40       123\n",
      "           2       0.30      0.39      0.34       143\n",
      "           3       0.75      0.44      0.55       647\n",
      "           4       0.45      0.68      0.54       193\n",
      "           5       0.14      0.20      0.16        45\n",
      "           6       0.19      0.23      0.21        47\n",
      "\n",
      "    accuracy                           0.48      1440\n",
      "   macro avg       0.38      0.43      0.39      1440\n",
      "weighted avg       0.55      0.48      0.49      1440\n",
      "\n",
      "Epoch [21/60] Accuracy: 0.6101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 64.55it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 84.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/60] Training Loss: 0.009793497598154594\n",
      "Epoch [22/60] Validation Loss: 0.010824067890644074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.63      0.56       242\n",
      "           1       0.32      0.50      0.39       123\n",
      "           2       0.26      0.32      0.29       143\n",
      "           3       0.76      0.43      0.55       647\n",
      "           4       0.50      0.62      0.56       193\n",
      "           5       0.10      0.22      0.14        45\n",
      "           6       0.12      0.19      0.15        47\n",
      "\n",
      "    accuracy                           0.47      1440\n",
      "   macro avg       0.37      0.42      0.38      1440\n",
      "weighted avg       0.56      0.47      0.49      1440\n",
      "\n",
      "Epoch [22/60] Accuracy: 0.6144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 65.98it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 85.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/60] Training Loss: 0.009740467405894754\n",
      "Epoch [23/60] Validation Loss: 0.010963945173554951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53       242\n",
      "           1       0.35      0.40      0.37       123\n",
      "           2       0.24      0.33      0.28       143\n",
      "           3       0.73      0.50      0.59       647\n",
      "           4       0.52      0.61      0.56       193\n",
      "           5       0.09      0.29      0.14        45\n",
      "           6       0.11      0.15      0.13        47\n",
      "\n",
      "    accuracy                           0.47      1440\n",
      "   macro avg       0.37      0.40      0.37      1440\n",
      "weighted avg       0.55      0.47      0.50      1440\n",
      "\n",
      "Epoch [23/60] Accuracy: 0.6246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 65.34it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 82.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/60] Training Loss: 0.00973161930461971\n",
      "Epoch [24/60] Validation Loss: 0.010960571302307976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.54       242\n",
      "           1       0.37      0.41      0.39       123\n",
      "           2       0.26      0.38      0.31       143\n",
      "           3       0.74      0.43      0.54       647\n",
      "           4       0.43      0.69      0.53       193\n",
      "           5       0.12      0.22      0.16        45\n",
      "           6       0.18      0.15      0.16        47\n",
      "\n",
      "    accuracy                           0.47      1440\n",
      "   macro avg       0.37      0.41      0.38      1440\n",
      "weighted avg       0.54      0.47      0.48      1440\n",
      "\n",
      "Epoch [24/60] Accuracy: 0.6278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 61.02it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 80.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/60] Training Loss: 0.009675548869270108\n",
      "Epoch [25/60] Validation Loss: 0.01090041349331538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.57      0.54       242\n",
      "           1       0.40      0.50      0.44       123\n",
      "           2       0.27      0.35      0.30       143\n",
      "           3       0.74      0.45      0.56       647\n",
      "           4       0.43      0.73      0.54       193\n",
      "           5       0.16      0.27      0.20        45\n",
      "           6       0.15      0.11      0.12        47\n",
      "\n",
      "    accuracy                           0.48      1440\n",
      "   macro avg       0.38      0.42      0.39      1440\n",
      "weighted avg       0.55      0.48      0.49      1440\n",
      "\n",
      "Epoch [25/60] Accuracy: 0.6333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 61.12it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 83.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/60] Training Loss: 0.009612570706333116\n",
      "Epoch [26/60] Validation Loss: 0.010946365114715364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.60      0.54       242\n",
      "           1       0.36      0.49      0.41       123\n",
      "           2       0.28      0.23      0.25       143\n",
      "           3       0.72      0.51      0.60       647\n",
      "           4       0.48      0.65      0.55       193\n",
      "           5       0.13      0.22      0.17        45\n",
      "           6       0.09      0.13      0.11        47\n",
      "\n",
      "    accuracy                           0.49      1440\n",
      "   macro avg       0.37      0.40      0.38      1440\n",
      "weighted avg       0.54      0.49      0.50      1440\n",
      "\n",
      "Epoch [26/60] Accuracy: 0.6418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 62.78it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 79.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/60] Training Loss: 0.009579265741147336\n",
      "Epoch [27/60] Validation Loss: 0.010992502172787985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.54      0.55       242\n",
      "           1       0.34      0.50      0.40       123\n",
      "           2       0.21      0.39      0.27       143\n",
      "           3       0.77      0.43      0.55       647\n",
      "           4       0.46      0.67      0.55       193\n",
      "           5       0.12      0.11      0.11        45\n",
      "           6       0.13      0.19      0.16        47\n",
      "\n",
      "    accuracy                           0.46      1440\n",
      "   macro avg       0.37      0.41      0.37      1440\n",
      "weighted avg       0.56      0.46      0.48      1440\n",
      "\n",
      "Epoch [27/60] Accuracy: 0.6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 61.79it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 84.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/60] Training Loss: 0.009568752027985027\n",
      "Epoch [28/60] Validation Loss: 0.010946026113298203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.54       242\n",
      "           1       0.37      0.39      0.38       123\n",
      "           2       0.30      0.33      0.31       143\n",
      "           3       0.70      0.57      0.63       647\n",
      "           4       0.50      0.68      0.57       193\n",
      "           5       0.15      0.18      0.16        45\n",
      "           6       0.10      0.15      0.12        47\n",
      "\n",
      "    accuracy                           0.51      1440\n",
      "   macro avg       0.38      0.40      0.39      1440\n",
      "weighted avg       0.54      0.51      0.52      1440\n",
      "\n",
      "Epoch [28/60] Accuracy: 0.6524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 60.55it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 74.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/60] Training Loss: 0.009538183091690862\n",
      "Epoch [29/60] Validation Loss: 0.010990498628881242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.58      0.53       242\n",
      "           1       0.30      0.54      0.39       123\n",
      "           2       0.31      0.20      0.24       143\n",
      "           3       0.73      0.52      0.61       647\n",
      "           4       0.46      0.72      0.56       193\n",
      "           5       0.15      0.16      0.15        45\n",
      "           6       0.11      0.09      0.10        47\n",
      "\n",
      "    accuracy                           0.50      1440\n",
      "   macro avg       0.37      0.40      0.37      1440\n",
      "weighted avg       0.54      0.50      0.50      1440\n",
      "\n",
      "Epoch [29/60] Accuracy: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 62.39it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 85.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/60] Training Loss: 0.00947218562241346\n",
      "Epoch [30/60] Validation Loss: 0.010992196367846594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.47      0.52       242\n",
      "           1       0.32      0.50      0.39       123\n",
      "           2       0.29      0.26      0.27       143\n",
      "           3       0.70      0.54      0.61       647\n",
      "           4       0.48      0.68      0.56       193\n",
      "           5       0.11      0.22      0.15        45\n",
      "           6       0.11      0.13      0.12        47\n",
      "\n",
      "    accuracy                           0.49      1440\n",
      "   macro avg       0.37      0.40      0.37      1440\n",
      "weighted avg       0.54      0.49      0.51      1440\n",
      "\n",
      "Epoch [30/60] Accuracy: 0.6677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 63.33it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 84.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/60] Training Loss: 0.00945003838832375\n",
      "Epoch [31/60] Validation Loss: 0.011019817739725112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.60      0.55       242\n",
      "           1       0.46      0.34      0.39       123\n",
      "           2       0.25      0.36      0.30       143\n",
      "           3       0.73      0.56      0.63       647\n",
      "           4       0.48      0.65      0.55       193\n",
      "           5       0.14      0.18      0.16        45\n",
      "           6       0.12      0.13      0.12        47\n",
      "\n",
      "    accuracy                           0.51      1440\n",
      "   macro avg       0.38      0.40      0.39      1440\n",
      "weighted avg       0.55      0.51      0.52      1440\n",
      "\n",
      "Epoch [31/60] Accuracy: 0.6788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 64.38it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 80.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/60] Training Loss: 0.009363344966782873\n",
      "Epoch [32/60] Validation Loss: 0.011000697811444601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.61      0.54       242\n",
      "           1       0.35      0.51      0.42       123\n",
      "           2       0.29      0.28      0.28       143\n",
      "           3       0.75      0.47      0.58       647\n",
      "           4       0.44      0.72      0.54       193\n",
      "           5       0.15      0.20      0.17        45\n",
      "           6       0.13      0.09      0.10        47\n",
      "\n",
      "    accuracy                           0.49      1440\n",
      "   macro avg       0.37      0.41      0.38      1440\n",
      "weighted avg       0.54      0.49      0.50      1440\n",
      "\n",
      "Epoch [32/60] Accuracy: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 56.66it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 84.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/60] Training Loss: 0.009368551825740985\n",
      "Epoch [33/60] Validation Loss: 0.010962545126676559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.55       242\n",
      "           1       0.29      0.50      0.37       123\n",
      "           2       0.24      0.24      0.24       143\n",
      "           3       0.73      0.52      0.61       647\n",
      "           4       0.51      0.65      0.57       193\n",
      "           5       0.11      0.16      0.13        45\n",
      "           6       0.10      0.15      0.12        47\n",
      "\n",
      "    accuracy                           0.49      1440\n",
      "   macro avg       0.36      0.39      0.37      1440\n",
      "weighted avg       0.54      0.49      0.50      1440\n",
      "\n",
      "Epoch [33/60] Accuracy: 0.6906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 62.42it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 84.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/60] Training Loss: 0.0093303694495212\n",
      "Epoch [34/60] Validation Loss: 0.011007475604613622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.55      0.55       242\n",
      "           1       0.37      0.34      0.35       123\n",
      "           2       0.26      0.34      0.30       143\n",
      "           3       0.72      0.57      0.64       647\n",
      "           4       0.47      0.70      0.56       193\n",
      "           5       0.16      0.16      0.16        45\n",
      "           6       0.12      0.15      0.13        47\n",
      "\n",
      "    accuracy                           0.52      1440\n",
      "   macro avg       0.38      0.40      0.39      1440\n",
      "weighted avg       0.55      0.52      0.52      1440\n",
      "\n",
      "Epoch [34/60] Accuracy: 0.6996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 59.48it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 74.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/60] Training Loss: 0.009319783030340105\n",
      "Epoch [35/60] Validation Loss: 0.011000904192527135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.52      0.55       242\n",
      "           1       0.35      0.44      0.39       123\n",
      "           2       0.23      0.30      0.26       143\n",
      "           3       0.70      0.56      0.62       647\n",
      "           4       0.50      0.66      0.57       193\n",
      "           5       0.13      0.13      0.13        45\n",
      "           6       0.13      0.17      0.15        47\n",
      "\n",
      "    accuracy                           0.50      1440\n",
      "   macro avg       0.37      0.40      0.38      1440\n",
      "weighted avg       0.54      0.50      0.52      1440\n",
      "\n",
      "Epoch [35/60] Accuracy: 0.6979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 57.90it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 80.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/60] Training Loss: 0.009306276840023909\n",
      "Epoch [36/60] Validation Loss: 0.011008931696414948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55       242\n",
      "           1       0.36      0.39      0.38       123\n",
      "           2       0.28      0.29      0.29       143\n",
      "           3       0.72      0.54      0.62       647\n",
      "           4       0.43      0.69      0.53       193\n",
      "           5       0.12      0.20      0.15        45\n",
      "           6       0.15      0.13      0.14        47\n",
      "\n",
      "    accuracy                           0.50      1440\n",
      "   macro avg       0.37      0.40      0.38      1440\n",
      "weighted avg       0.54      0.50      0.51      1440\n",
      "\n",
      "Epoch [36/60] Accuracy: 0.7010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 62.28it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 85.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/60] Training Loss: 0.009271951563125937\n",
      "Epoch [37/60] Validation Loss: 0.010973230169879066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55       242\n",
      "           1       0.31      0.47      0.37       123\n",
      "           2       0.25      0.29      0.27       143\n",
      "           3       0.71      0.58      0.64       647\n",
      "           4       0.49      0.62      0.54       193\n",
      "           5       0.20      0.20      0.20        45\n",
      "           6       0.15      0.09      0.11        47\n",
      "\n",
      "    accuracy                           0.51      1440\n",
      "   macro avg       0.38      0.40      0.38      1440\n",
      "weighted avg       0.54      0.51      0.52      1440\n",
      "\n",
      "Epoch [37/60] Accuracy: 0.7121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 64.88it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 84.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/60] Training Loss: 0.00923304600280654\n",
      "Epoch [38/60] Validation Loss: 0.010987622621986602\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.53      0.56       242\n",
      "           1       0.30      0.42      0.35       123\n",
      "           2       0.29      0.37      0.33       143\n",
      "           3       0.71      0.57      0.63       647\n",
      "           4       0.49      0.68      0.57       193\n",
      "           5       0.21      0.11      0.14        45\n",
      "           6       0.13      0.15      0.14        47\n",
      "\n",
      "    accuracy                           0.52      1440\n",
      "   macro avg       0.39      0.40      0.39      1440\n",
      "weighted avg       0.55      0.52      0.52      1440\n",
      "\n",
      "Epoch [38/60] Accuracy: 0.7196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 61.02it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 72.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/60] Training Loss: 0.009208347920919641\n",
      "Epoch [39/60] Validation Loss: 0.010998642527394825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55       242\n",
      "           1       0.34      0.47      0.40       123\n",
      "           2       0.24      0.41      0.30       143\n",
      "           3       0.73      0.50      0.59       647\n",
      "           4       0.45      0.67      0.54       193\n",
      "           5       0.17      0.11      0.13        45\n",
      "           6       0.18      0.11      0.13        47\n",
      "\n",
      "    accuracy                           0.49      1440\n",
      "   macro avg       0.38      0.40      0.38      1440\n",
      "weighted avg       0.55      0.49      0.50      1440\n",
      "\n",
      "Epoch [39/60] Accuracy: 0.7258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 61.25it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 78.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/60] Training Loss: 0.009185519865634102\n",
      "Epoch [40/60] Validation Loss: 0.011006150974167718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.55       242\n",
      "           1       0.34      0.46      0.39       123\n",
      "           2       0.28      0.30      0.29       143\n",
      "           3       0.69      0.60      0.64       647\n",
      "           4       0.49      0.59      0.54       193\n",
      "           5       0.17      0.11      0.14        45\n",
      "           6       0.20      0.11      0.14        47\n",
      "\n",
      "    accuracy                           0.52      1440\n",
      "   macro avg       0.39      0.39      0.38      1440\n",
      "weighted avg       0.53      0.52      0.52      1440\n",
      "\n",
      "Epoch [40/60] Accuracy: 0.7298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 58.92it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 74.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/60] Training Loss: 0.009154731607347083\n",
      "Epoch [41/60] Validation Loss: 0.010999043782552084\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.56       242\n",
      "           1       0.42      0.45      0.43       123\n",
      "           2       0.29      0.28      0.28       143\n",
      "           3       0.69      0.62      0.65       647\n",
      "           4       0.50      0.61      0.55       193\n",
      "           5       0.18      0.22      0.20        45\n",
      "           6       0.16      0.09      0.11        47\n",
      "\n",
      "    accuracy                           0.54      1440\n",
      "   macro avg       0.39      0.41      0.40      1440\n",
      "weighted avg       0.54      0.54      0.54      1440\n",
      "\n",
      "Epoch [41/60] Accuracy: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 63.86it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 75.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/60] Training Loss: 0.009130786533905413\n",
      "Epoch [42/60] Validation Loss: 0.010971618940432866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.55       242\n",
      "           1       0.48      0.33      0.39       123\n",
      "           2       0.28      0.38      0.32       143\n",
      "           3       0.71      0.58      0.64       647\n",
      "           4       0.46      0.67      0.55       193\n",
      "           5       0.18      0.22      0.20        45\n",
      "           6       0.13      0.13      0.13        47\n",
      "\n",
      "    accuracy                           0.52      1440\n",
      "   macro avg       0.40      0.41      0.40      1440\n",
      "weighted avg       0.55      0.52      0.53      1440\n",
      "\n",
      "Epoch [42/60] Accuracy: 0.7379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 59.24it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 82.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/60] Training Loss: 0.009103978284132168\n",
      "Epoch [43/60] Validation Loss: 0.011004926843775643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.50      0.53       242\n",
      "           1       0.37      0.41      0.39       123\n",
      "           2       0.25      0.33      0.28       143\n",
      "           3       0.71      0.57      0.63       647\n",
      "           4       0.46      0.70      0.56       193\n",
      "           5       0.16      0.16      0.16        45\n",
      "           6       0.11      0.09      0.10        47\n",
      "\n",
      "    accuracy                           0.51      1440\n",
      "   macro avg       0.37      0.39      0.38      1440\n",
      "weighted avg       0.54      0.51      0.52      1440\n",
      "\n",
      "Epoch [43/60] Accuracy: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 57.47it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 81.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/60] Training Loss: 0.009092514802105997\n",
      "Epoch [44/60] Validation Loss: 0.010981727474265629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.62      0.56       242\n",
      "           1       0.38      0.48      0.42       123\n",
      "           2       0.34      0.20      0.25       143\n",
      "           3       0.72      0.55      0.62       647\n",
      "           4       0.43      0.72      0.54       193\n",
      "           5       0.18      0.22      0.20        45\n",
      "           6       0.13      0.09      0.10        47\n",
      "\n",
      "    accuracy                           0.52      1440\n",
      "   macro avg       0.38      0.41      0.39      1440\n",
      "weighted avg       0.54      0.52      0.52      1440\n",
      "\n",
      "Epoch [44/60] Accuracy: 0.7430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 63.40it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 85.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/60] Training Loss: 0.009060130789612928\n",
      "Epoch [45/60] Validation Loss: 0.010996332267920177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.52      0.55       242\n",
      "           1       0.41      0.44      0.42       123\n",
      "           2       0.26      0.40      0.32       143\n",
      "           3       0.71      0.60      0.65       647\n",
      "           4       0.47      0.63      0.54       193\n",
      "           5       0.16      0.13      0.14        45\n",
      "           6       0.19      0.13      0.15        47\n",
      "\n",
      "    accuracy                           0.53      1440\n",
      "   macro avg       0.40      0.41      0.40      1440\n",
      "weighted avg       0.55      0.53      0.53      1440\n",
      "\n",
      "Epoch [45/60] Accuracy: 0.7538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 64.52it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 86.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/60] Training Loss: 0.009028431631013554\n",
      "Epoch [46/60] Validation Loss: 0.011002060688204236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.48      0.53       242\n",
      "           1       0.35      0.46      0.40       123\n",
      "           2       0.28      0.33      0.30       143\n",
      "           3       0.68      0.63      0.65       647\n",
      "           4       0.50      0.62      0.55       193\n",
      "           5       0.14      0.16      0.15        45\n",
      "           6       0.25      0.11      0.15        47\n",
      "\n",
      "    accuracy                           0.53      1440\n",
      "   macro avg       0.40      0.40      0.39      1440\n",
      "weighted avg       0.54      0.53      0.53      1440\n",
      "\n",
      "Epoch [46/60] Accuracy: 0.7595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 58.23it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 79.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/60] Training Loss: 0.009008989720540697\n",
      "Epoch [47/60] Validation Loss: 0.011016697436571122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54       242\n",
      "           1       0.37      0.41      0.39       123\n",
      "           2       0.28      0.29      0.28       143\n",
      "           3       0.70      0.60      0.64       647\n",
      "           4       0.47      0.66      0.55       193\n",
      "           5       0.18      0.18      0.18        45\n",
      "           6       0.17      0.09      0.11        47\n",
      "\n",
      "    accuracy                           0.52      1440\n",
      "   macro avg       0.38      0.40      0.39      1440\n",
      "weighted avg       0.53      0.52      0.52      1440\n",
      "\n",
      "Epoch [47/60] Accuracy: 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 62.97it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 76.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/60] Training Loss: 0.008993288401616149\n",
      "Epoch [48/60] Validation Loss: 0.010945163501633538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.55       242\n",
      "           1       0.34      0.41      0.37       123\n",
      "           2       0.32      0.31      0.31       143\n",
      "           3       0.72      0.58      0.64       647\n",
      "           4       0.46      0.67      0.55       193\n",
      "           5       0.14      0.18      0.16        45\n",
      "           6       0.13      0.13      0.13        47\n",
      "\n",
      "    accuracy                           0.52      1440\n",
      "   macro avg       0.38      0.40      0.39      1440\n",
      "weighted avg       0.55      0.52      0.53      1440\n",
      "\n",
      "Epoch [48/60] Accuracy: 0.7642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 57.57it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 81.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/60] Training Loss: 0.008976903706801253\n",
      "Epoch [49/60] Validation Loss: 0.011017270882924398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.55      0.56       242\n",
      "           1       0.32      0.43      0.37       123\n",
      "           2       0.28      0.34      0.30       143\n",
      "           3       0.71      0.59      0.64       647\n",
      "           4       0.48      0.70      0.57       193\n",
      "           5       0.19      0.13      0.16        45\n",
      "           6       0.13      0.06      0.09        47\n",
      "\n",
      "    accuracy                           0.53      1440\n",
      "   macro avg       0.38      0.40      0.38      1440\n",
      "weighted avg       0.54      0.53      0.53      1440\n",
      "\n",
      "Epoch [49/60] Accuracy: 0.7657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 63.24it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 82.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/60] Training Loss: 0.008959442007589618\n",
      "Epoch [50/60] Validation Loss: 0.011077672491470974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.55      0.52       242\n",
      "           1       0.41      0.38      0.40       123\n",
      "           2       0.31      0.24      0.27       143\n",
      "           3       0.66      0.63      0.65       647\n",
      "           4       0.46      0.62      0.53       193\n",
      "           5       0.13      0.13      0.13        45\n",
      "           6       0.15      0.09      0.11        47\n",
      "\n",
      "    accuracy                           0.52      1440\n",
      "   macro avg       0.38      0.38      0.37      1440\n",
      "weighted avg       0.52      0.52      0.52      1440\n",
      "\n",
      "Epoch [50/60] Accuracy: 0.7721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 61.43it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 79.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/60] Training Loss: 0.008945308018224032\n",
      "Epoch [51/60] Validation Loss: 0.011083671864536073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.50      0.53       242\n",
      "           1       0.35      0.48      0.41       123\n",
      "           2       0.26      0.38      0.31       143\n",
      "           3       0.69      0.59      0.64       647\n",
      "           4       0.47      0.56      0.52       193\n",
      "           5       0.17      0.11      0.13        45\n",
      "           6       0.14      0.09      0.11        47\n",
      "\n",
      "    accuracy                           0.51      1440\n",
      "   macro avg       0.38      0.39      0.38      1440\n",
      "weighted avg       0.53      0.51      0.52      1440\n",
      "\n",
      "Epoch [51/60] Accuracy: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 57.34it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 74.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/60] Training Loss: 0.008946462182225789\n",
      "Epoch [52/60] Validation Loss: 0.011110685682959026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.53       242\n",
      "           1       0.39      0.42      0.40       123\n",
      "           2       0.26      0.35      0.30       143\n",
      "           3       0.70      0.58      0.63       647\n",
      "           4       0.46      0.59      0.51       193\n",
      "           5       0.15      0.09      0.11        45\n",
      "           6       0.13      0.15      0.14        47\n",
      "\n",
      "    accuracy                           0.51      1440\n",
      "   macro avg       0.37      0.39      0.38      1440\n",
      "weighted avg       0.53      0.51      0.51      1440\n",
      "\n",
      "Epoch [52/60] Accuracy: 0.7733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 59.52it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 74.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/60] Training Loss: 0.008949228838087351\n",
      "Epoch [53/60] Validation Loss: 0.011067213531997468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.53       242\n",
      "           1       0.49      0.33      0.40       123\n",
      "           2       0.29      0.31      0.30       143\n",
      "           3       0.69      0.59      0.64       647\n",
      "           4       0.41      0.68      0.51       193\n",
      "           5       0.15      0.18      0.16        45\n",
      "           6       0.15      0.09      0.11        47\n",
      "\n",
      "    accuracy                           0.51      1440\n",
      "   macro avg       0.39      0.39      0.38      1440\n",
      "weighted avg       0.54      0.51      0.52      1440\n",
      "\n",
      "Epoch [53/60] Accuracy: 0.7763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 63.73it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 82.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/60] Training Loss: 0.00892780573754311\n",
      "Epoch [54/60] Validation Loss: 0.011053984695010715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.52      0.53       242\n",
      "           1       0.42      0.37      0.40       123\n",
      "           2       0.29      0.28      0.28       143\n",
      "           3       0.68      0.65      0.66       647\n",
      "           4       0.47      0.64      0.54       193\n",
      "           5       0.19      0.16      0.17        45\n",
      "           6       0.12      0.11      0.11        47\n",
      "\n",
      "    accuracy                           0.53      1440\n",
      "   macro avg       0.39      0.39      0.39      1440\n",
      "weighted avg       0.53      0.53      0.53      1440\n",
      "\n",
      "Epoch [54/60] Accuracy: 0.7827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 65.56it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 83.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/60] Training Loss: 0.008895438912956475\n",
      "Epoch [55/60] Validation Loss: 0.011093658291631274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.53       242\n",
      "           1       0.38      0.37      0.37       123\n",
      "           2       0.32      0.32      0.32       143\n",
      "           3       0.66      0.64      0.65       647\n",
      "           4       0.46      0.60      0.52       193\n",
      "           5       0.17      0.18      0.17        45\n",
      "           6       0.11      0.09      0.10        47\n",
      "\n",
      "    accuracy                           0.52      1440\n",
      "   macro avg       0.38      0.38      0.38      1440\n",
      "weighted avg       0.52      0.52      0.52      1440\n",
      "\n",
      "Epoch [55/60] Accuracy: 0.7855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 62.16it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 83.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/60] Training Loss: 0.008869588145071165\n",
      "Epoch [56/60] Validation Loss: 0.011054403500424491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.56      0.54       242\n",
      "           1       0.38      0.34      0.36       123\n",
      "           2       0.26      0.30      0.28       143\n",
      "           3       0.68      0.60      0.64       647\n",
      "           4       0.48      0.63      0.54       193\n",
      "           5       0.18      0.18      0.18        45\n",
      "           6       0.12      0.09      0.10        47\n",
      "\n",
      "    accuracy                           0.52      1440\n",
      "   macro avg       0.38      0.39      0.38      1440\n",
      "weighted avg       0.52      0.52      0.52      1440\n",
      "\n",
      "Epoch [56/60] Accuracy: 0.7906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 61.39it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 85.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/60] Training Loss: 0.008876389564086928\n",
      "Epoch [57/60] Validation Loss: 0.011091531813144683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.64      0.53       242\n",
      "           1       0.33      0.41      0.36       123\n",
      "           2       0.33      0.30      0.31       143\n",
      "           3       0.69      0.50      0.58       647\n",
      "           4       0.45      0.62      0.53       193\n",
      "           5       0.19      0.13      0.16        45\n",
      "           6       0.09      0.11      0.10        47\n",
      "\n",
      "    accuracy                           0.49      1440\n",
      "   macro avg       0.36      0.39      0.37      1440\n",
      "weighted avg       0.52      0.49      0.49      1440\n",
      "\n",
      "Epoch [57/60] Accuracy: 0.7947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 64.71it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 83.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/60] Training Loss: 0.008863559672863616\n",
      "Epoch [58/60] Validation Loss: 0.011095650576882892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.62      0.56       242\n",
      "           1       0.47      0.32      0.38       123\n",
      "           2       0.31      0.29      0.30       143\n",
      "           3       0.68      0.63      0.65       647\n",
      "           4       0.46      0.63      0.53       193\n",
      "           5       0.16      0.11      0.13        45\n",
      "           6       0.13      0.11      0.12        47\n",
      "\n",
      "    accuracy                           0.53      1440\n",
      "   macro avg       0.39      0.39      0.38      1440\n",
      "weighted avg       0.53      0.53      0.53      1440\n",
      "\n",
      "Epoch [58/60] Accuracy: 0.7940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 60.93it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 83.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/60] Training Loss: 0.008830132444500581\n",
      "Epoch [59/60] Validation Loss: 0.011055617200003729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.61      0.56       242\n",
      "           1       0.44      0.38      0.41       123\n",
      "           2       0.29      0.39      0.33       143\n",
      "           3       0.69      0.60      0.64       647\n",
      "           4       0.48      0.60      0.53       193\n",
      "           5       0.16      0.09      0.11        45\n",
      "           6       0.13      0.09      0.10        47\n",
      "\n",
      "    accuracy                           0.53      1440\n",
      "   macro avg       0.39      0.39      0.38      1440\n",
      "weighted avg       0.54      0.53      0.53      1440\n",
      "\n",
      "Epoch [59/60] Accuracy: 0.8029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 64.38it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 83.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/60] Training Loss: 0.008819393428815332\n",
      "Epoch [60/60] Validation Loss: 0.011170582721630733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.48      0.52       242\n",
      "           1       0.44      0.38      0.41       123\n",
      "           2       0.26      0.35      0.29       143\n",
      "           3       0.66      0.68      0.67       647\n",
      "           4       0.53      0.54      0.53       193\n",
      "           5       0.19      0.18      0.18        45\n",
      "           6       0.21      0.09      0.12        47\n",
      "\n",
      "    accuracy                           0.54      1440\n",
      "   macro avg       0.41      0.39      0.39      1440\n",
      "weighted avg       0.54      0.54      0.53      1440\n",
      "\n",
      "Epoch [60/60] Accuracy: 0.8072\n",
      "Training complete!\n",
      "=========================BEST MODEL DETAILS=========================\n",
      "Best model at epoch 7 with validation loss: 15.513537287712097\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.63      0.54       242\n",
      "           1       0.41      0.47      0.44       123\n",
      "           2       0.37      0.15      0.21       143\n",
      "           3       0.75      0.43      0.55       647\n",
      "           4       0.44      0.67      0.53       193\n",
      "           5       0.13      0.36      0.19        45\n",
      "           6       0.11      0.28      0.15        47\n",
      "\n",
      "    accuracy                           0.47      1440\n",
      "   macro avg       0.38      0.43      0.37      1440\n",
      "weighted avg       0.55      0.47      0.48      1440\n",
      "\n",
      "Best model saved at: /tmp/semeval24_task3/baseline_models/emotion_models/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Define your model\n",
    "# model = EmotionClassifier(input_size=11237, hidden_size=5000, num_layers=2, num_heads=2, dropout=0.2, num_emotions=7)\n",
    "model = EmotionClassifier(input_size=768*2+1024, hidden_size=2000, num_emotions=7)\n",
    "model.to(\"cuda\")\n",
    "print(TEXT_EMBEDDINGS_FILEPATH)\n",
    "print(AUDIO_EMBEDDINGS_FILEPATH)\n",
    "print(VIDEO_EMBEDDINGS_FILEPATH)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "weights_tensor = torch.tensor(np.array(indexer.weights)).to(\"cuda\").float()\n",
    "# weights_tensor = torch.tensor(np.array([1.0, 1.0, 1.0, 0.25, 1.0, 3.0, 3.0])).to(\"cuda\").float()\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=weights_tensor,\n",
    "    ignore_index=7\n",
    ")\n",
    "\n",
    "num_epochs = 60\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "best_model_file = None\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = -1\n",
    "best_classification_report = None\n",
    "\n",
    "\n",
    "# criterion = FocalLoss(gamma=2.0)\n",
    "\n",
    "# Define training parameters\n",
    "\n",
    "# Training loop\n",
    "for epoch in (range(num_epochs)):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader):  # Assuming you have a DataLoader for your dataset\n",
    "        # Extract data from the batch\n",
    "        audio = batch['audio'].to('cuda')\n",
    "        video = batch['video'].to('cuda')\n",
    "        text = batch['text'].to('cuda')\n",
    "        emotion_indices = batch['emotion_labels'].to('cuda')\n",
    "        pad_mask = batch['pad_mask'].to('cuda')\n",
    "\n",
    "        # Forward pass\n",
    "        emotion_logits = model(audio, video, text)\n",
    "\n",
    "        # Reshape emotion_logits\n",
    "        emotion_logits = emotion_logits.view(-1, emotion_logits.size(-1))\n",
    "\n",
    "        # Flatten emotion_indices (assuming it's a 2D tensor with shape [batch_size, max_sequence_length])\n",
    "        emotion_indices = emotion_indices.view(-1)\n",
    "\n",
    "        # Calculate a mask to exclude padded positions from the loss\n",
    "        pad_mask = pad_mask.view(-1).float()\n",
    "\n",
    "        # Calculate the loss, excluding padded positions\n",
    "        loss = criterion(emotion_logits, emotion_indices)\n",
    "        # masked_loss = torch.sum(loss * pad_mask) / torch.sum(pad_mask)\n",
    "        masked_loss = loss# *pad_mask\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        masked_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        total_loss += masked_loss.item()\n",
    "        total_tokens += torch.sum(pad_mask).item()\n",
    "        \n",
    "        predicted_emotions = torch.argmax(emotion_logits, dim=1)\n",
    "        correct_predictions = ((predicted_emotions == emotion_indices) * pad_mask).sum().item()\n",
    "\n",
    "        total_correct += correct_predictions\n",
    "        total_predictions += torch.sum(pad_mask).item()  # Batch size\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_val_loss = 0.0\n",
    "    total_val_tokens = 0\n",
    "    total_val_correct = 0\n",
    "    total_val_predictions = 0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    padded_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in tqdm(validation_dataloader):\n",
    "            audio = val_batch['audio'].to('cuda')\n",
    "            video = val_batch['video'].to('cuda')\n",
    "            text = val_batch['text'].to('cuda')\n",
    "            emotion_indices = val_batch['emotion_labels'].to('cuda')\n",
    "            pad_mask = val_batch['pad_mask'].to('cuda')\n",
    "\n",
    "            emotion_logits = model(audio, video, text)\n",
    "\n",
    "            # Reshape emotion_logits\n",
    "            emotion_logits = emotion_logits.view(-1, emotion_logits.size(-1))\n",
    "\n",
    "            # Flatten emotion_indices (assuming it's a 2D tensor with shape [batch_size, max_sequence_length])\n",
    "            emotion_indices = emotion_indices.view(-1)\n",
    "\n",
    "            pad_mask = pad_mask.view(-1)   \n",
    "\n",
    "            # Calculate the loss, excluding padded positions\n",
    "            val_loss = criterion(emotion_logits, emotion_indices)\n",
    "            masked_loss = torch.sum(val_loss * pad_mask) / torch.sum(pad_mask)\n",
    "            \n",
    "            total_val_loss += masked_loss.item()\n",
    "            total_val_tokens += torch.sum(pad_mask).item()\n",
    "            \n",
    "            predicted_emotions_val = torch.argmax(emotion_logits, dim=1)\n",
    "            correct_predictions_val = ((predicted_emotions_val == emotion_indices) * pad_mask).sum().item()\n",
    "            total_val_correct += correct_predictions_val\n",
    "            total_val_predictions += torch.sum(pad_mask).item()\n",
    "\n",
    "            # Store true and predicted labels for F1 score calculation\n",
    "            true_labels.extend(emotion_indices.cpu().numpy())\n",
    "            predicted_labels.extend(predicted_emotions_val.cpu().numpy())\n",
    "            padded_labels.extend(pad_mask.cpu().numpy())\n",
    "\n",
    "    final_true_labels = [label for label, pad in zip(true_labels, padded_labels) if pad == 1]\n",
    "    final_predicted_labels = [label for label, pad in zip(predicted_labels, padded_labels) if pad == 1]\n",
    "    # print(\"=========================\")\n",
    "    # print(final_true_labels)\n",
    "    # print(final_predicted_labels)\n",
    "    # print(\"=========================\")\n",
    "    classification_rep = classification_report(final_true_labels, final_predicted_labels)\n",
    "    \n",
    "    if total_val_loss < best_val_loss:\n",
    "        best_val_loss = total_val_loss\n",
    "        best_epoch = epoch\n",
    "        best_classification_report = classification_rep\n",
    "        best_model_file = f\"/tmp/semeval24_task3/baseline_models/emotion_models/best_model.pt\"\n",
    "        torch.save(model.state_dict(), best_model_file)\n",
    "\n",
    "    # Calculate and print the average loss for this epoch\n",
    "    avg_loss = total_loss / total_tokens\n",
    "    avg_val_loss = total_val_loss / total_val_tokens\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Training Loss: {avg_loss}\")\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Validation Loss: {avg_val_loss}\")\n",
    "    print(classification_rep)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Accuracy: {total_correct / total_predictions:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"/tmp/semeval24_task3/baseline_models/emotion_models/emotion_model_{epoch:02}.pt\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(\"=========================BEST MODEL DETAILS=========================\")\n",
    "print(f\"Best model at epoch {best_epoch + 1} with validation loss: {best_val_loss}\")\n",
    "print(\"Classification Report\\n\", best_classification_report)\n",
    "print(f\"Best model saved at: {best_model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
