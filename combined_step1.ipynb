{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8ed30e-65a3-4e55-bc32-2694490898f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1236\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "TRAIN_FILE_PATH = \"/tmp/semeval24_task3/final_clean_data/train/Subtask_2.json\"\n",
    "VALIDATION_FILE_PATH = \"/tmp/semeval24_task3/final_clean_data/val/Subtask_2.json\"\n",
    "with open(TRAIN_FILE_PATH) as f:\n",
    "    train_data = json.load(f)\n",
    "with open(VALIDATION_FILE_PATH) as f:\n",
    "    validation_data = json.load(f)\n",
    "\n",
    "pprint(len(train_data))\n",
    "pprint(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2075, 1008, 1489, 5258, 1670, 376, 340]\n",
      "[0.00048192771084337347, 0.000992063492063492, 0.000671591672263264, 0.0001901863826550019, 0.0005988023952095808, 0.0026595744680851063, 0.0029411764705882353]\n"
     ]
    }
   ],
   "source": [
    "class EmotionIndexer:\n",
    "    def __init__(self):\n",
    "        self.emotion_to_index = {\n",
    "            'joy': 0,\n",
    "            'sadness': 1,\n",
    "            'anger': 2,\n",
    "            'neutral': 3,\n",
    "            'surprise': 4,\n",
    "            'disgust': 5,\n",
    "            'fear': 6,\n",
    "            'pad': 7,\n",
    "        }\n",
    "        self.emotion_freq = [0]*7\n",
    "        self.weights = None\n",
    "\n",
    "        self.index_to_emotion = {index: emotion for emotion, index in self.emotion_to_index.items()}\n",
    "\n",
    "    def emotion_to_idx(self, emotion):\n",
    "        return self.emotion_to_index.get(emotion, None)\n",
    "\n",
    "    def idx_to_emotion(self, index):\n",
    "        return self.index_to_emotion.get(index, None)\n",
    "    \n",
    "    def compute_weights(self, data):\n",
    "        for conversation in data:\n",
    "            conversation = conversation['conversation']\n",
    "            for utterance in conversation:\n",
    "                emotion = utterance['emotion']\n",
    "                self.emotion_freq[self.emotion_to_index[emotion]] += 1\n",
    "        print(self.emotion_freq)\n",
    "        self.weights = [1/freq for freq in self.emotion_freq]\n",
    "\n",
    "# Example usage\n",
    "indexer = EmotionIndexer()\n",
    "indexer.compute_weights(train_data)\n",
    "print(indexer.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/akshett.jindal/miniconda3/envs/semeval24-task3/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_video\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "class YourAudioEncoder():\n",
    "    def __init__(self, audio_embeddings_path):\n",
    "        with open(audio_embeddings_path, \"rb\") as f:\n",
    "            self.audio_embeddings = pickle.load(f)\n",
    "\n",
    "    def lmao(self, audio_name):\n",
    "        audio_name = audio_name.split(\".\")[0]\n",
    "        audio_embedding = self.audio_embeddings[audio_name]\n",
    "        return torch.from_numpy(audio_embedding)\n",
    "    \n",
    "class YourVideoEncoder():\n",
    "    def __init__(self, video_embeddings_path):\n",
    "        with open(video_embeddings_path, \"rb\") as f:\n",
    "            self.video_embeddings = pickle.load(f)\n",
    "\n",
    "    def lmao(self, video_name):\n",
    "        # video_name = video_name.split(\".\")[0]\n",
    "        video_embedding = self.video_embeddings[video_name].reshape((16,-1))\n",
    "        video_embedding = np.mean(video_embedding, axis=0)\n",
    "        return torch.from_numpy(video_embedding)\n",
    "\n",
    "class YourTextEncoder():\n",
    "    def __init__(self, text_embeddings_path):\n",
    "        with open(text_embeddings_path, \"rb\") as f:\n",
    "            self.text_embeddings = pickle.load(f)\n",
    "\n",
    "    def lmao(self, video_name):\n",
    "        text_embedding = self.text_embeddings[video_name]\n",
    "        return torch.from_numpy(text_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, json_file, audio_encoder, video_encoder, text_encoder, max_seq_len):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.data = self.load_data(json_file)\n",
    "        self.audio_encoder = audio_encoder\n",
    "        self.video_encoder = video_encoder\n",
    "        self.text_encoder = text_encoder\n",
    "\n",
    "    def load_data(self, json_file):\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        conversation = self.data[idx]['conversation']\n",
    "        emotion_labels = [utterance['emotion'] for utterance in conversation]\n",
    "        audio_paths = [utterance['video_name'].replace('mp4', 'wav') for utterance in conversation]\n",
    "        video_paths = [utterance['video_name'] for utterance in conversation]\n",
    "        texts = [utterance['video_name'] for utterance in conversation]\n",
    "\n",
    "        audio_embeddings = [self.audio_encoder.lmao(audio_path) for audio_path in audio_paths]\n",
    "        video_embeddings = [self.video_encoder.lmao(video_path) for video_path in video_paths]\n",
    "        text_embeddings = [self.text_encoder.lmao(text) for text in texts]\n",
    "\n",
    "        cause_pairs = self.data[idx]['emotion-cause_pairs']\n",
    "        useful_utterances = set([int(cause_pair[1]) for cause_pair in cause_pairs])\n",
    "        cause_labels = []\n",
    "        for utterance in conversation:\n",
    "            if utterance['utterance_ID'] in useful_utterances:\n",
    "                cause_labels.append(1)\n",
    "            else:\n",
    "                cause_labels.append(0)\n",
    "        \n",
    "        \n",
    "        # Pad or truncate conversations to the maximum sequence length\n",
    "        if len(conversation) < self.max_seq_len:\n",
    "            pad_length = self.max_seq_len - len(conversation)\n",
    "            audio_embeddings += [torch.zeros_like(audio_embeddings[0])] * pad_length\n",
    "            video_embeddings += [torch.zeros_like(video_embeddings[0])] * pad_length\n",
    "            text_embeddings += [torch.zeros_like(text_embeddings[0])] * pad_length\n",
    "            cause_labels += [-1] * pad_length\n",
    "            emotion_labels += ['pad'] * pad_length\n",
    "            pad_mask = [1] * len(conversation) + [0] * pad_length\n",
    "        else:\n",
    "            audio_embeddings = audio_embeddings[:self.max_seq_len]\n",
    "            video_embeddings = video_embeddings[:self.max_seq_len]\n",
    "            text_embeddings = text_embeddings[:self.max_seq_len]\n",
    "            emotion_labels = emotion_labels[:self.max_seq_len]\n",
    "            cause_labels = cause_labels[:self.max_seq_len]\n",
    "            pad_mask = [1] * self.max_seq_len\n",
    "\n",
    "        emotion_indices = [indexer.emotion_to_idx(emotion) for emotion in emotion_labels]\n",
    "        \n",
    "        audio_embeddings = torch.stack(audio_embeddings)\n",
    "        video_embeddings = torch.stack(video_embeddings)\n",
    "        text_embeddings = torch.stack(text_embeddings)\n",
    "        emotion_indices = torch.from_numpy(np.array(emotion_indices))\n",
    "        pad_mask = torch.from_numpy(np.array(pad_mask))\n",
    "        cause_labels = torch.from_numpy(np.array(cause_labels))\n",
    "        \n",
    "        return {\n",
    "            'audio': audio_embeddings,\n",
    "            'video': video_embeddings,\n",
    "            'text': text_embeddings,\n",
    "            'emotion_labels': emotion_indices,\n",
    "            'pad_mask': pad_mask,\n",
    "            'cause_labels': cause_labels,\n",
    "        }\n",
    "# Example usage\n",
    "# You need to define your audio, video, and text encoders accordingly\n",
    "\n",
    "# Define your data paths\n",
    "DATA_DIR = \"/tmp/semeval24_task3\"\n",
    "\n",
    "AUDIO_EMBEDDINGS_FILEPATH = os.path.join(DATA_DIR, \"audio_embeddings\", \"audio_embeddings.pkl\")\n",
    "VIDEO_EMBEDDINGS_FILEPATH = os.path.join(DATA_DIR, \"video_embeddings\", \"train\", \"video_embeddings.pkl\")\n",
    "TEXT_EMBEDDINGS_FILEPATH = os.path.join(DATA_DIR, \"text_embeddings\", \"text_embeddings.pkl\")\n",
    "\n",
    "audio_encoder = YourAudioEncoder(AUDIO_EMBEDDINGS_FILEPATH)\n",
    "video_encoder = YourVideoEncoder(VIDEO_EMBEDDINGS_FILEPATH)\n",
    "text_encoder = YourTextEncoder(TEXT_EMBEDDINGS_FILEPATH)\n",
    "max_seq_len = 40  # Adjust this according to your needs\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "train_dataset = ConversationDataset(TRAIN_FILE_PATH, audio_encoder, video_encoder, text_encoder, max_seq_len)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "validation_dataset = ConversationDataset(VALIDATION_FILE_PATH, audio_encoder, video_encoder, text_encoder, max_seq_len)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Example of iterating through batches\n",
    "# for batch in dataloader:\n",
    "#     audio = batch['audio']  # Shape: (batch_size, max_seq_len, audio_embedding_size)\n",
    "#     video = batch['video']  # Shape: (batch_size, max_seq_len, video_embedding_size)\n",
    "#     text = batch['text']    # Shape: (batch_size, max_seq_len, text_embedding_size)\n",
    "#     emotions = batch['emotion_labels']  # List of emotion labels for each utterance in the batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, num_emotions, embedding_dropout=0.2):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        \n",
    "        self.audio_dropout = nn.Dropout(embedding_dropout)\n",
    "        self.video_dropout = nn.Dropout(embedding_dropout)\n",
    "        self.text_dropout = nn.Dropout(embedding_dropout)\n",
    "\n",
    "        self.first_linear = nn.Linear(input_size, hidden_size, dtype=torch.float32)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.second_linear_layer = nn.Linear(hidden_size, hidden_size, dtype=torch.float32)\n",
    "        # Replace Transformer with BiLSTM\n",
    "        self.bilstm = nn.LSTM(hidden_size, hidden_size // 2, num_layers, \n",
    "                              dropout=dropout, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, num_emotions)\n",
    "\n",
    "    def forward(self, audio_encoding, video_encoding, text_encoding):\n",
    "        # Concatenate or combine the audio, video, and text encodings\n",
    "        audio_encoding = audio_encoding.float()\n",
    "        video_encoding = video_encoding.float()\n",
    "        text_encoding = text_encoding.float().squeeze()\n",
    "        \n",
    "        audio_encoding = self.audio_dropout(audio_encoding)\n",
    "        video_encoding = self.video_dropout(video_encoding)\n",
    "        text_encoding = self.text_dropout(text_encoding)\n",
    "        \n",
    "        combined_encoding = torch.cat((audio_encoding, video_encoding, text_encoding), dim=2)\n",
    "        \n",
    "        combined_encoding = self.first_linear(combined_encoding)\n",
    "        combined_encoding = self.relu(combined_encoding)\n",
    "        combined_encoding = self.second_linear_layer(combined_encoding)\n",
    "        \n",
    "        # Pass through BiLSTM\n",
    "        lstm_output, _ = self.bilstm(combined_encoding)\n",
    "\n",
    "        # Take the output of the BiLSTM\n",
    "        emotion_logits = self.linear(lstm_output)\n",
    "        # Apply a softmax layer\n",
    "        emotion_logits = torch.softmax(emotion_logits, dim=2)\n",
    "\n",
    "        return emotion_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.53it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.20it/s]\n",
      "/home2/akshett.jindal/miniconda3/envs/semeval24-task3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/akshett.jindal/miniconda3/envs/semeval24-task3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/akshett.jindal/miniconda3/envs/semeval24-task3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [1/30] Training Loss: 0.016602963326253686\n",
      "Epoch [1/30] Accuracy: 0.12459070072036674\n",
      "Epoch [1/30] Accuracy: 0.5833333333333334\n",
      "VALIDATION METRICS\n",
      "Epoch [1/30] Validation Loss: 0.01626831484282773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.32      0.35       226\n",
      "           1       0.11      0.91      0.19       139\n",
      "           2       0.12      0.02      0.03       126\n",
      "           3       0.33      0.00      0.01       671\n",
      "           4       0.00      0.00      0.00       170\n",
      "           5       0.00      0.00      0.00        38\n",
      "           6       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.15      1403\n",
      "   macro avg       0.13      0.18      0.08      1403\n",
      "weighted avg       0.24      0.15      0.08      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69       795\n",
      "           1       0.60      0.58      0.59       608\n",
      "\n",
      "    accuracy                           0.65      1403\n",
      "   macro avg       0.64      0.64      0.64      1403\n",
      "weighted avg       0.65      0.65      0.65      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.55it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.15it/s]\n",
      "/home2/akshett.jindal/miniconda3/envs/semeval24-task3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/akshett.jindal/miniconda3/envs/semeval24-task3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/akshett.jindal/miniconda3/envs/semeval24-task3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [2/30] Training Loss: 0.01596294467403909\n",
      "Epoch [2/30] Accuracy: 0.2767681728880157\n",
      "Epoch [2/30] Accuracy: 0.6635559921414538\n",
      "VALIDATION METRICS\n",
      "Epoch [2/30] Validation Loss: 0.015792115959879848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.39      0.39       226\n",
      "           1       0.20      0.62      0.30       139\n",
      "           2       0.35      0.23      0.28       126\n",
      "           3       0.61      0.39      0.48       671\n",
      "           4       0.11      0.12      0.12       170\n",
      "           5       0.00      0.00      0.00        38\n",
      "           6       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.35      1403\n",
      "   macro avg       0.24      0.25      0.22      1403\n",
      "weighted avg       0.42      0.35      0.36      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.68       795\n",
      "           1       0.60      0.75      0.67       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.68      0.68      0.67      1403\n",
      "weighted avg       0.69      0.67      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.53it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [3/30] Training Loss: 0.015730331302391758\n",
      "Epoch [3/30] Accuracy: 0.3204813359528487\n",
      "Epoch [3/30] Accuracy: 0.6819744597249509\n",
      "VALIDATION METRICS\n",
      "Epoch [3/30] Validation Loss: 0.01570970334075471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.60      0.43       226\n",
      "           1       0.25      0.39      0.30       139\n",
      "           2       0.37      0.22      0.28       126\n",
      "           3       0.62      0.41      0.49       671\n",
      "           4       0.14      0.06      0.08       170\n",
      "           5       0.06      0.03      0.04        38\n",
      "           6       0.03      0.18      0.06        33\n",
      "\n",
      "    accuracy                           0.36      1403\n",
      "   macro avg       0.26      0.27      0.24      1403\n",
      "weighted avg       0.43      0.36      0.37      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72       795\n",
      "           1       0.64      0.64      0.64       608\n",
      "\n",
      "    accuracy                           0.69      1403\n",
      "   macro avg       0.68      0.68      0.68      1403\n",
      "weighted avg       0.69      0.69      0.69      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.55it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [4/30] Training Loss: 0.015484334326446173\n",
      "Epoch [4/30] Accuracy: 0.2991977734119188\n",
      "Epoch [4/30] Accuracy: 0.7093156516044532\n",
      "VALIDATION METRICS\n",
      "Epoch [4/30] Validation Loss: 0.015683837219042516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.65      0.43       226\n",
      "           1       0.22      0.57      0.32       139\n",
      "           2       0.33      0.36      0.34       126\n",
      "           3       0.66      0.31      0.42       671\n",
      "           4       0.21      0.08      0.11       170\n",
      "           5       0.07      0.03      0.04        38\n",
      "           6       0.02      0.03      0.02        33\n",
      "\n",
      "    accuracy                           0.35      1403\n",
      "   macro avg       0.26      0.29      0.24      1403\n",
      "weighted avg       0.45      0.35      0.35      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.68       795\n",
      "           1       0.60      0.75      0.67       608\n",
      "\n",
      "    accuracy                           0.68      1403\n",
      "   macro avg       0.68      0.68      0.68      1403\n",
      "weighted avg       0.69      0.68      0.68      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.53it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [5/30] Training Loss: 0.015244627904486016\n",
      "Epoch [5/30] Accuracy: 0.3519155206286837\n",
      "Epoch [5/30] Accuracy: 0.7243778650949574\n",
      "VALIDATION METRICS\n",
      "Epoch [5/30] Validation Loss: 0.015744045472365995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.46      0.40       226\n",
      "           1       0.36      0.36      0.36       139\n",
      "           2       0.19      0.63      0.29       126\n",
      "           3       0.75      0.20      0.32       671\n",
      "           4       0.18      0.15      0.16       170\n",
      "           5       0.07      0.13      0.09        38\n",
      "           6       0.02      0.12      0.04        33\n",
      "\n",
      "    accuracy                           0.29      1403\n",
      "   macro avg       0.28      0.29      0.24      1403\n",
      "weighted avg       0.49      0.29      0.30      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74       795\n",
      "           1       0.67      0.51      0.58       608\n",
      "\n",
      "    accuracy                           0.68      1403\n",
      "   macro avg       0.68      0.66      0.66      1403\n",
      "weighted avg       0.68      0.68      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.51it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [6/30] Training Loss: 0.014984979610780368\n",
      "Epoch [6/30] Accuracy: 0.3713163064833006\n",
      "Epoch [6/30] Accuracy: 0.7431237721021611\n",
      "VALIDATION METRICS\n",
      "Epoch [6/30] Validation Loss: 0.015659619125398837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.71      0.45       226\n",
      "           1       0.34      0.37      0.36       139\n",
      "           2       0.38      0.29      0.33       126\n",
      "           3       0.73      0.31      0.43       671\n",
      "           4       0.29      0.32      0.30       170\n",
      "           5       0.11      0.26      0.15        38\n",
      "           6       0.05      0.15      0.07        33\n",
      "\n",
      "    accuracy                           0.37      1403\n",
      "   macro avg       0.32      0.34      0.30      1403\n",
      "weighted avg       0.51      0.37      0.39      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.54      0.64       795\n",
      "           1       0.57      0.80      0.67       608\n",
      "\n",
      "    accuracy                           0.66      1403\n",
      "   macro avg       0.68      0.67      0.65      1403\n",
      "weighted avg       0.69      0.66      0.65      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.47it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [7/30] Training Loss: 0.014690236691641666\n",
      "Epoch [7/30] Accuracy: 0.40970857891290113\n",
      "Epoch [7/30] Accuracy: 0.7583497053045186\n",
      "VALIDATION METRICS\n",
      "Epoch [7/30] Validation Loss: 0.015405610894103264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.52      0.44       226\n",
      "           1       0.33      0.42      0.37       139\n",
      "           2       0.26      0.44      0.32       126\n",
      "           3       0.77      0.29      0.42       671\n",
      "           4       0.31      0.47      0.38       170\n",
      "           5       0.05      0.13      0.07        38\n",
      "           6       0.06      0.18      0.09        33\n",
      "\n",
      "    accuracy                           0.37      1403\n",
      "   macro avg       0.31      0.35      0.30      1403\n",
      "weighted avg       0.53      0.37      0.39      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.70       795\n",
      "           1       0.61      0.72      0.66       608\n",
      "\n",
      "    accuracy                           0.68      1403\n",
      "   macro avg       0.68      0.69      0.68      1403\n",
      "weighted avg       0.69      0.68      0.68      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.49it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [8/30] Training Loss: 0.014465112797793955\n",
      "Epoch [8/30] Accuracy: 0.4341028159790439\n",
      "Epoch [8/30] Accuracy: 0.7718565815324165\n",
      "VALIDATION METRICS\n",
      "Epoch [8/30] Validation Loss: 0.015384562425076409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.63      0.46       226\n",
      "           1       0.34      0.42      0.38       139\n",
      "           2       0.35      0.31      0.33       126\n",
      "           3       0.77      0.32      0.45       671\n",
      "           4       0.37      0.55      0.44       170\n",
      "           5       0.04      0.13      0.07        38\n",
      "           6       0.05      0.12      0.07        33\n",
      "\n",
      "    accuracy                           0.40      1403\n",
      "   macro avg       0.33      0.35      0.31      1403\n",
      "weighted avg       0.54      0.40      0.42      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74       795\n",
      "           1       0.67      0.50      0.57       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.67      0.65      0.65      1403\n",
      "weighted avg       0.67      0.67      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.46it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [9/30] Training Loss: 0.014217123477070177\n",
      "Epoch [9/30] Accuracy: 0.44687295350360184\n",
      "Epoch [9/30] Accuracy: 0.7910117878192534\n",
      "VALIDATION METRICS\n",
      "Epoch [9/30] Validation Loss: 0.015364433303528484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.60      0.49       226\n",
      "           1       0.40      0.40      0.40       139\n",
      "           2       0.38      0.33      0.35       126\n",
      "           3       0.75      0.49      0.59       671\n",
      "           4       0.46      0.51      0.48       170\n",
      "           5       0.10      0.26      0.14        38\n",
      "           6       0.05      0.15      0.08        33\n",
      "\n",
      "    accuracy                           0.47      1403\n",
      "   macro avg       0.36      0.39      0.36      1403\n",
      "weighted avg       0.56      0.47      0.50      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.82      0.73       795\n",
      "           1       0.64      0.44      0.52       608\n",
      "\n",
      "    accuracy                           0.65      1403\n",
      "   macro avg       0.65      0.63      0.62      1403\n",
      "weighted avg       0.65      0.65      0.64      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.49it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [10/30] Training Loss: 0.013961650162798638\n",
      "Epoch [10/30] Accuracy: 0.48313686967910935\n",
      "Epoch [10/30] Accuracy: 0.8067288801571709\n",
      "VALIDATION METRICS\n",
      "Epoch [10/30] Validation Loss: 0.01530679922314601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.47      0.48       226\n",
      "           1       0.25      0.65      0.36       139\n",
      "           2       0.42      0.25      0.31       126\n",
      "           3       0.71      0.51      0.59       671\n",
      "           4       0.59      0.39      0.47       170\n",
      "           5       0.15      0.18      0.16        38\n",
      "           6       0.08      0.27      0.12        33\n",
      "\n",
      "    accuracy                           0.47      1403\n",
      "   macro avg       0.38      0.39      0.36      1403\n",
      "weighted avg       0.56      0.47      0.49      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.62      0.67       795\n",
      "           1       0.58      0.69      0.63       608\n",
      "\n",
      "    accuracy                           0.65      1403\n",
      "   macro avg       0.66      0.66      0.65      1403\n",
      "weighted avg       0.66      0.65      0.66      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.49it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [11/30] Training Loss: 0.013864370366679193\n",
      "Epoch [11/30] Accuracy: 0.48068107400130977\n",
      "Epoch [11/30] Accuracy: 0.8154060248853962\n",
      "VALIDATION METRICS\n",
      "Epoch [11/30] Validation Loss: 0.015328149836316588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.56      0.48       226\n",
      "           1       0.45      0.38      0.41       139\n",
      "           2       0.33      0.44      0.38       126\n",
      "           3       0.75      0.55      0.63       671\n",
      "           4       0.47      0.55      0.51       170\n",
      "           5       0.06      0.11      0.07        38\n",
      "           6       0.08      0.15      0.11        33\n",
      "\n",
      "    accuracy                           0.50      1403\n",
      "   macro avg       0.37      0.39      0.37      1403\n",
      "weighted avg       0.56      0.50      0.52      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.59      0.66       795\n",
      "           1       0.58      0.73      0.64       608\n",
      "\n",
      "    accuracy                           0.65      1403\n",
      "   macro avg       0.66      0.66      0.65      1403\n",
      "weighted avg       0.67      0.65      0.65      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.51it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [12/30] Training Loss: 0.013767698366187645\n",
      "Epoch [12/30] Accuracy: 0.4868205631958088\n",
      "Epoch [12/30] Accuracy: 0.8277668631303209\n",
      "VALIDATION METRICS\n",
      "Epoch [12/30] Validation Loss: 0.015395584228798397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46       226\n",
      "           1       0.31      0.49      0.38       139\n",
      "           2       0.32      0.25      0.28       126\n",
      "           3       0.76      0.41      0.54       671\n",
      "           4       0.36      0.66      0.46       170\n",
      "           5       0.06      0.11      0.08        38\n",
      "           6       0.08      0.18      0.11        33\n",
      "\n",
      "    accuracy                           0.44      1403\n",
      "   macro avg       0.33      0.37      0.33      1403\n",
      "weighted avg       0.54      0.44      0.45      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.68       795\n",
      "           1       0.60      0.70      0.65       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.67      0.67      0.66      1403\n",
      "weighted avg       0.68      0.67      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.50it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [13/30] Training Loss: 0.013553160581232756\n",
      "Epoch [13/30] Accuracy: 0.514652914210871\n",
      "Epoch [13/30] Accuracy: 0.8365258677144728\n",
      "VALIDATION METRICS\n",
      "Epoch [13/30] Validation Loss: 0.015268016014452586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.63      0.49       226\n",
      "           1       0.40      0.43      0.42       139\n",
      "           2       0.35      0.25      0.29       126\n",
      "           3       0.76      0.48      0.59       671\n",
      "           4       0.39      0.62      0.48       170\n",
      "           5       0.07      0.11      0.08        38\n",
      "           6       0.09      0.15      0.12        33\n",
      "\n",
      "    accuracy                           0.48      1403\n",
      "   macro avg       0.35      0.38      0.35      1403\n",
      "weighted avg       0.55      0.48      0.49      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.68       795\n",
      "           1       0.60      0.71      0.65       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.67      0.67      0.67      1403\n",
      "weighted avg       0.68      0.67      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.48it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [14/30] Training Loss: 0.013408343924286324\n",
      "Epoch [14/30] Accuracy: 0.5134250163719711\n",
      "Epoch [14/30] Accuracy: 0.8513425016371972\n",
      "VALIDATION METRICS\n",
      "Epoch [14/30] Validation Loss: 0.015192707691206222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.42      0.45       226\n",
      "           1       0.30      0.50      0.38       139\n",
      "           2       0.38      0.25      0.30       126\n",
      "           3       0.72      0.56      0.63       671\n",
      "           4       0.54      0.49      0.51       170\n",
      "           5       0.12      0.26      0.17        38\n",
      "           6       0.08      0.33      0.13        33\n",
      "\n",
      "    accuracy                           0.48      1403\n",
      "   macro avg       0.37      0.40      0.36      1403\n",
      "weighted avg       0.56      0.48      0.51      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73       795\n",
      "           1       0.65      0.49      0.56       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.66      0.64      0.64      1403\n",
      "weighted avg       0.66      0.67      0.66      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.46it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [15/30] Training Loss: 0.013329598489116827\n",
      "Epoch [15/30] Accuracy: 0.5140798952193845\n",
      "Epoch [15/30] Accuracy: 0.8587917485265226\n",
      "VALIDATION METRICS\n",
      "Epoch [15/30] Validation Loss: 0.015184817616631962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.39      0.44       226\n",
      "           1       0.41      0.45      0.42       139\n",
      "           2       0.32      0.23      0.27       126\n",
      "           3       0.73      0.55      0.63       671\n",
      "           4       0.38      0.66      0.48       170\n",
      "           5       0.08      0.21      0.11        38\n",
      "           6       0.06      0.18      0.10        33\n",
      "\n",
      "    accuracy                           0.48      1403\n",
      "   macro avg       0.36      0.38      0.35      1403\n",
      "weighted avg       0.55      0.48      0.50      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72       795\n",
      "           1       0.63      0.60      0.61       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.67      0.67      0.67      1403\n",
      "weighted avg       0.67      0.67      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.45it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [16/30] Training Loss: 0.013200528075590428\n",
      "Epoch [16/30] Accuracy: 0.5387197118533071\n",
      "Epoch [16/30] Accuracy: 0.8677144728225278\n",
      "VALIDATION METRICS\n",
      "Epoch [16/30] Validation Loss: 0.0153422771992211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.49      0.51       226\n",
      "           1       0.36      0.43      0.39       139\n",
      "           2       0.32      0.37      0.35       126\n",
      "           3       0.73      0.54      0.62       671\n",
      "           4       0.45      0.54      0.49       170\n",
      "           5       0.06      0.13      0.08        38\n",
      "           6       0.08      0.21      0.11        33\n",
      "\n",
      "    accuracy                           0.49      1403\n",
      "   macro avg       0.36      0.39      0.37      1403\n",
      "weighted avg       0.56      0.49      0.51      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.69       795\n",
      "           1       0.61      0.69      0.65       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.67      0.67      0.67      1403\n",
      "weighted avg       0.68      0.67      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.47it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [17/30] Training Loss: 0.013083028594262474\n",
      "Epoch [17/30] Accuracy: 0.5391290111329404\n",
      "Epoch [17/30] Accuracy: 0.8778650949574329\n",
      "VALIDATION METRICS\n",
      "Epoch [17/30] Validation Loss: 0.015436699453287267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.42      0.44       226\n",
      "           1       0.42      0.37      0.40       139\n",
      "           2       0.33      0.21      0.26       126\n",
      "           3       0.75      0.40      0.53       671\n",
      "           4       0.39      0.62      0.48       170\n",
      "           5       0.08      0.26      0.12        38\n",
      "           6       0.06      0.42      0.11        33\n",
      "\n",
      "    accuracy                           0.41      1403\n",
      "   macro avg       0.36      0.39      0.33      1403\n",
      "weighted avg       0.56      0.41      0.45      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.60      0.67       795\n",
      "           1       0.59      0.75      0.66       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.68      0.68      0.67      1403\n",
      "weighted avg       0.69      0.67      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.48it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [18/30] Training Loss: 0.013073115809024668\n",
      "Epoch [18/30] Accuracy: 0.5457596594629993\n",
      "Epoch [18/30] Accuracy: 0.8735265225933202\n",
      "VALIDATION METRICS\n",
      "Epoch [18/30] Validation Loss: 0.015409691709326746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.56      0.49       226\n",
      "           1       0.49      0.34      0.40       139\n",
      "           2       0.27      0.47      0.34       126\n",
      "           3       0.77      0.46      0.58       671\n",
      "           4       0.39      0.62      0.48       170\n",
      "           5       0.03      0.05      0.04        38\n",
      "           6       0.10      0.18      0.13        33\n",
      "\n",
      "    accuracy                           0.47      1403\n",
      "   macro avg       0.35      0.38      0.35      1403\n",
      "weighted avg       0.56      0.47      0.49      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67       795\n",
      "           1       0.59      0.73      0.65       608\n",
      "\n",
      "    accuracy                           0.66      1403\n",
      "   macro avg       0.67      0.67      0.66      1403\n",
      "weighted avg       0.68      0.66      0.66      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.48it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [19/30] Training Loss: 0.012880599120120715\n",
      "Epoch [19/30] Accuracy: 0.5722822527832351\n",
      "Epoch [19/30] Accuracy: 0.888015717092338\n",
      "VALIDATION METRICS\n",
      "Epoch [19/30] Validation Loss: 0.015141748651299235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50       226\n",
      "           1       0.40      0.42      0.41       139\n",
      "           2       0.33      0.32      0.32       126\n",
      "           3       0.76      0.61      0.68       671\n",
      "           4       0.48      0.62      0.54       170\n",
      "           5       0.07      0.16      0.10        38\n",
      "           6       0.11      0.18      0.14        33\n",
      "\n",
      "    accuracy                           0.53      1403\n",
      "   macro avg       0.38      0.40      0.38      1403\n",
      "weighted avg       0.57      0.53      0.55      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68       795\n",
      "           1       0.59      0.67      0.63       608\n",
      "\n",
      "    accuracy                           0.66      1403\n",
      "   macro avg       0.66      0.66      0.66      1403\n",
      "weighted avg       0.66      0.66      0.66      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.48it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [20/30] Training Loss: 0.012812301418948345\n",
      "Epoch [20/30] Accuracy: 0.5654060248853962\n",
      "Epoch [20/30] Accuracy: 0.8902259332023575\n",
      "VALIDATION METRICS\n",
      "Epoch [20/30] Validation Loss: 0.01529141774112976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.42      0.44       226\n",
      "           1       0.32      0.53      0.40       139\n",
      "           2       0.32      0.38      0.35       126\n",
      "           3       0.77      0.49      0.60       671\n",
      "           4       0.45      0.59      0.51       170\n",
      "           5       0.07      0.18      0.10        38\n",
      "           6       0.07      0.15      0.10        33\n",
      "\n",
      "    accuracy                           0.47      1403\n",
      "   macro avg       0.35      0.39      0.36      1403\n",
      "weighted avg       0.56      0.47      0.50      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       795\n",
      "           1       0.61      0.64      0.62       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.66      0.66      0.66      1403\n",
      "weighted avg       0.67      0.67      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.50it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [21/30] Training Loss: 0.01277720978936106\n",
      "Epoch [21/30] Accuracy: 0.5737557301899149\n",
      "Epoch [21/30] Accuracy: 0.8914538310412574\n",
      "VALIDATION METRICS\n",
      "Epoch [21/30] Validation Loss: 0.015284454661102186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.47      0.48       226\n",
      "           1       0.34      0.45      0.39       139\n",
      "           2       0.30      0.13      0.19       126\n",
      "           3       0.74      0.59      0.65       671\n",
      "           4       0.49      0.57      0.53       170\n",
      "           5       0.10      0.24      0.14        38\n",
      "           6       0.07      0.27      0.11        33\n",
      "\n",
      "    accuracy                           0.49      1403\n",
      "   macro avg       0.36      0.39      0.36      1403\n",
      "weighted avg       0.56      0.49      0.52      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.74       795\n",
      "           1       0.67      0.47      0.55       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.67      0.65      0.65      1403\n",
      "weighted avg       0.67      0.67      0.66      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.47it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [22/30] Training Loss: 0.012696504475794044\n",
      "Epoch [22/30] Accuracy: 0.5672069417157826\n",
      "Epoch [22/30] Accuracy: 0.9012770137524558\n",
      "VALIDATION METRICS\n",
      "Epoch [22/30] Validation Loss: 0.015277909280908848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.56      0.49       226\n",
      "           1       0.40      0.47      0.44       139\n",
      "           2       0.28      0.34      0.31       126\n",
      "           3       0.76      0.52      0.62       671\n",
      "           4       0.47      0.61      0.53       170\n",
      "           5       0.06      0.11      0.07        38\n",
      "           6       0.09      0.12      0.10        33\n",
      "\n",
      "    accuracy                           0.50      1403\n",
      "   macro avg       0.36      0.39      0.37      1403\n",
      "weighted avg       0.56      0.50      0.51      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       795\n",
      "           1       0.64      0.60      0.62       608\n",
      "\n",
      "    accuracy                           0.68      1403\n",
      "   macro avg       0.67      0.67      0.67      1403\n",
      "weighted avg       0.68      0.68      0.68      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.51it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [23/30] Training Loss: 0.012530249546537543\n",
      "Epoch [23/30] Accuracy: 0.5858709888670596\n",
      "Epoch [23/30] Accuracy: 0.9115094957432875\n",
      "VALIDATION METRICS\n",
      "Epoch [23/30] Validation Loss: 0.01541694078968834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50       226\n",
      "           1       0.34      0.46      0.39       139\n",
      "           2       0.38      0.20      0.26       126\n",
      "           3       0.72      0.66      0.69       671\n",
      "           4       0.61      0.49      0.55       170\n",
      "           5       0.13      0.16      0.14        38\n",
      "           6       0.06      0.21      0.09        33\n",
      "\n",
      "    accuracy                           0.53      1403\n",
      "   macro avg       0.39      0.38      0.37      1403\n",
      "weighted avg       0.57      0.53      0.54      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67       795\n",
      "           1       0.58      0.63      0.60       608\n",
      "\n",
      "    accuracy                           0.64      1403\n",
      "   macro avg       0.64      0.64      0.64      1403\n",
      "weighted avg       0.64      0.64      0.64      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.51it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [24/30] Training Loss: 0.012501782434550312\n",
      "Epoch [24/30] Accuracy: 0.5884086444007859\n",
      "Epoch [24/30] Accuracy: 0.9129829731499672\n",
      "VALIDATION METRICS\n",
      "Epoch [24/30] Validation Loss: 0.015417287626694715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.41      0.47       226\n",
      "           1       0.44      0.34      0.38       139\n",
      "           2       0.24      0.49      0.33       126\n",
      "           3       0.76      0.51      0.61       671\n",
      "           4       0.48      0.56      0.52       170\n",
      "           5       0.06      0.13      0.08        38\n",
      "           6       0.08      0.30      0.12        33\n",
      "\n",
      "    accuracy                           0.47      1403\n",
      "   macro avg       0.37      0.39      0.36      1403\n",
      "weighted avg       0.58      0.47      0.50      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71       795\n",
      "           1       0.62      0.57      0.59       608\n",
      "\n",
      "    accuracy                           0.66      1403\n",
      "   macro avg       0.65      0.65      0.65      1403\n",
      "weighted avg       0.66      0.66      0.66      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.48it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [25/30] Training Loss: 0.012383244477929675\n",
      "Epoch [25/30] Accuracy: 0.6052717747216765\n",
      "Epoch [25/30] Accuracy: 0.9166666666666666\n",
      "VALIDATION METRICS\n",
      "Epoch [25/30] Validation Loss: 0.015398573552551052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.48      0.47       226\n",
      "           1       0.43      0.46      0.45       139\n",
      "           2       0.32      0.31      0.31       126\n",
      "           3       0.76      0.56      0.64       671\n",
      "           4       0.44      0.59      0.50       170\n",
      "           5       0.08      0.18      0.11        38\n",
      "           6       0.08      0.21      0.12        33\n",
      "\n",
      "    accuracy                           0.50      1403\n",
      "   macro avg       0.37      0.40      0.37      1403\n",
      "weighted avg       0.57      0.50      0.52      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68       795\n",
      "           1       0.59      0.65      0.61       608\n",
      "\n",
      "    accuracy                           0.65      1403\n",
      "   macro avg       0.65      0.65      0.65      1403\n",
      "weighted avg       0.65      0.65      0.65      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.47it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [26/30] Training Loss: 0.012433992260877963\n",
      "Epoch [26/30] Accuracy: 0.5960216110019646\n",
      "Epoch [26/30] Accuracy: 0.9206777996070727\n",
      "VALIDATION METRICS\n",
      "Epoch [26/30] Validation Loss: 0.01528094431713319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.51      0.49       226\n",
      "           1       0.39      0.43      0.41       139\n",
      "           2       0.38      0.18      0.25       126\n",
      "           3       0.74      0.58      0.65       671\n",
      "           4       0.42      0.66      0.52       170\n",
      "           5       0.09      0.24      0.13        38\n",
      "           6       0.10      0.15      0.12        33\n",
      "\n",
      "    accuracy                           0.51      1403\n",
      "   macro avg       0.37      0.39      0.37      1403\n",
      "weighted avg       0.56      0.51      0.52      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.72       795\n",
      "           1       0.63      0.54      0.58       608\n",
      "\n",
      "    accuracy                           0.66      1403\n",
      "   macro avg       0.65      0.65      0.65      1403\n",
      "weighted avg       0.66      0.66      0.66      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.47it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [27/30] Training Loss: 0.012370064210563839\n",
      "Epoch [27/30] Accuracy: 0.6050261951538966\n",
      "Epoch [27/30] Accuracy: 0.9201866404715128\n",
      "VALIDATION METRICS\n",
      "Epoch [27/30] Validation Loss: 0.015053165528235568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.58      0.50       226\n",
      "           1       0.39      0.43      0.41       139\n",
      "           2       0.35      0.28      0.31       126\n",
      "           3       0.75      0.58      0.65       671\n",
      "           4       0.56      0.54      0.55       170\n",
      "           5       0.10      0.16      0.12        38\n",
      "           6       0.12      0.39      0.18        33\n",
      "\n",
      "    accuracy                           0.52      1403\n",
      "   macro avg       0.39      0.42      0.39      1403\n",
      "weighted avg       0.57      0.52      0.54      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       795\n",
      "           1       0.63      0.60      0.61       608\n",
      "\n",
      "    accuracy                           0.68      1403\n",
      "   macro avg       0.67      0.67      0.67      1403\n",
      "weighted avg       0.67      0.68      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.49it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [28/30] Training Loss: 0.012304722852931743\n",
      "Epoch [28/30] Accuracy: 0.6074001309757695\n",
      "Epoch [28/30] Accuracy: 0.9237066142763589\n",
      "VALIDATION METRICS\n",
      "Epoch [28/30] Validation Loss: 0.015218304636133457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.57      0.53       226\n",
      "           1       0.38      0.41      0.39       139\n",
      "           2       0.28      0.24      0.26       126\n",
      "           3       0.74      0.62      0.68       671\n",
      "           4       0.51      0.60      0.55       170\n",
      "           5       0.07      0.16      0.10        38\n",
      "           6       0.15      0.18      0.16        33\n",
      "\n",
      "    accuracy                           0.53      1403\n",
      "   macro avg       0.38      0.40      0.38      1403\n",
      "weighted avg       0.56      0.53      0.54      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71       795\n",
      "           1       0.62      0.63      0.62       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.66      0.66      0.66      1403\n",
      "weighted avg       0.67      0.67      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.46it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [29/30] Training Loss: 0.01230332754996374\n",
      "Epoch [29/30] Accuracy: 0.6150130975769482\n",
      "Epoch [29/30] Accuracy: 0.923215455140799\n",
      "VALIDATION METRICS\n",
      "Epoch [29/30] Validation Loss: 0.015353747460983178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.53      0.51       226\n",
      "           1       0.51      0.33      0.40       139\n",
      "           2       0.28      0.40      0.33       126\n",
      "           3       0.74      0.60      0.66       671\n",
      "           4       0.50      0.58      0.54       170\n",
      "           5       0.05      0.13      0.08        38\n",
      "           6       0.13      0.21      0.16        33\n",
      "\n",
      "    accuracy                           0.52      1403\n",
      "   macro avg       0.39      0.40      0.38      1403\n",
      "weighted avg       0.57      0.52      0.54      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.70       795\n",
      "           1       0.61      0.66      0.63       608\n",
      "\n",
      "    accuracy                           0.67      1403\n",
      "   macro avg       0.66      0.67      0.66      1403\n",
      "weighted avg       0.67      0.67      0.67      1403\n",
      "\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:17<00:00,  4.51it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training data metrics\n",
      "Epoch [30/30] Training Loss: 0.012175424901503867\n",
      "Epoch [30/30] Accuracy: 0.6268009168303864\n",
      "Epoch [30/30] Accuracy: 0.9300098231827112\n",
      "VALIDATION METRICS\n",
      "Epoch [30/30] Validation Loss: 0.015228467419244354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.54      0.47       226\n",
      "           1       0.34      0.50      0.41       139\n",
      "           2       0.29      0.32      0.30       126\n",
      "           3       0.79      0.45      0.58       671\n",
      "           4       0.43      0.62      0.51       170\n",
      "           5       0.06      0.18      0.09        38\n",
      "           6       0.12      0.12      0.12        33\n",
      "\n",
      "    accuracy                           0.47      1403\n",
      "   macro avg       0.35      0.39      0.36      1403\n",
      "weighted avg       0.56      0.47      0.49      1403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68       795\n",
      "           1       0.59      0.71      0.64       608\n",
      "\n",
      "    accuracy                           0.66      1403\n",
      "   macro avg       0.66      0.67      0.66      1403\n",
      "weighted avg       0.67      0.66      0.66      1403\n",
      "\n",
      "===============================\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Define your model\n",
    "# model = EmotionClassifier(input_size=11237, hidden_size=5000, num_layers=2, num_heads=2, dropout=0.2, num_emotions=7)\n",
    "emotion_model = EmotionClassifier(input_size=768*3, hidden_size=2000, num_layers=3, dropout=0.6, num_emotions=7)\n",
    "cause_model = EmotionClassifier(input_size=768*3, hidden_size=2000, num_layers=2, dropout=0.6, num_emotions=2)\n",
    "emotion_model.to(\"cuda\")\n",
    "cause_model.to(\"cuda\")\n",
    "\n",
    "weights_tensor = torch.tensor(np.array(indexer.weights)).to(\"cuda\").float()\n",
    "emotion_criterion = nn.CrossEntropyLoss(\n",
    "    weight=weights_tensor,\n",
    "    ignore_index=7\n",
    ")\n",
    "\n",
    "cause_criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "num_epochs = 30\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "\n",
    "emotion_optimizer = AdamW(emotion_model.parameters(), lr=0.0001)\n",
    "emotion_lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    emotion_optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "cause_optimizer = AdamW(cause_model.parameters(), lr=1e-4)\n",
    "cause_lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    cause_optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "\n",
    "# Define training parameters\n",
    "\n",
    "# Training loop\n",
    "for epoch in (range(num_epochs)):\n",
    "    emotion_model.train()  # Set the model to training mode\n",
    "    cause_model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    total_correct_emotions = 0\n",
    "    total_correct_causes = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader):  # Assuming you have a DataLoader for your dataset\n",
    "        # Extract data from the batch\n",
    "        audio = batch['audio'].to('cuda')\n",
    "        video = batch['video'].to('cuda')\n",
    "        text = batch['text'].to('cuda')\n",
    "        cause_indices = batch['cause_labels'].to('cuda')\n",
    "        \n",
    "        audio_copy = audio.clone().detach()\n",
    "        video_copy = video.clone().detach()\n",
    "        text_copy = text.clone().detach()\n",
    "        \n",
    "        emotion_indices = batch['emotion_labels'].to('cuda')\n",
    "        pad_mask = batch['pad_mask'].to('cuda')\n",
    "\n",
    "        # Forward pass\n",
    "        emotion_logits = emotion_model(audio_copy, video_copy, text_copy)\n",
    "\n",
    "        # Reshape emotion_logits\n",
    "        emotion_logits = emotion_logits.view(-1, emotion_logits.size(-1))\n",
    "\n",
    "        # Flatten emotion_indices (assuming it's a 2D tensor with shape [batch_size, max_sequence_length])\n",
    "        emotion_indices = emotion_indices.view(-1)\n",
    "\n",
    "        # Calculate a mask to exclude padded positions from the loss\n",
    "        pad_mask = pad_mask.view(-1).float()\n",
    "\n",
    "        # Calculate the loss, excluding padded positions\n",
    "        emotion_loss = emotion_criterion(emotion_logits, emotion_indices)\n",
    "        # masked_loss = torch.sum(loss * pad_mask) / torch.sum(pad_mask)\n",
    "        masked_loss = emotion_loss# *pad_mask\n",
    "        # Backpropagation and optimization\n",
    "        \n",
    "        \n",
    "        cause_logits = cause_model(audio, video, text)\n",
    "        cause_logits = cause_logits.view(-1, cause_logits.size(-1))\n",
    "        cause_indices = cause_indices.view(-1)\n",
    "        \n",
    "        cause_loss = cause_criterion(cause_logits, cause_indices)\n",
    "        masked_loss += cause_loss\n",
    "        \n",
    "        emotion_optimizer.zero_grad()\n",
    "        cause_optimizer.zero_grad()\n",
    "        \n",
    "        masked_loss.backward()\n",
    "        \n",
    "        emotion_optimizer.step()\n",
    "        cause_optimizer.step()        \n",
    "\n",
    "        total_loss += masked_loss.item()\n",
    "        total_tokens += torch.sum(pad_mask).item()\n",
    "        \n",
    "        predicted_emotions = torch.argmax(emotion_logits, dim=1)\n",
    "        correct_predictions_emotions = ((predicted_emotions == emotion_indices) * pad_mask).sum().item()\n",
    "\n",
    "        predicted_causes = torch.argmax(cause_logits, dim=1)\n",
    "        correct_predictions_causes = ((predicted_causes == cause_indices) * pad_mask).sum().item()\n",
    "        \n",
    "        total_correct_emotions += correct_predictions_emotions\n",
    "        total_correct_causes += correct_predictions_causes\n",
    "        total_predictions += torch.sum(pad_mask).item()  # Batch size\n",
    "        \n",
    "    \n",
    "    emotion_lr_scheduler.step()\n",
    "    cause_lr_scheduler.step()\n",
    "    \n",
    "    emotion_model.eval()  # Set the model to evaluation mode\n",
    "    cause_model.eval()\n",
    "    \n",
    "    total_val_loss = 0.0\n",
    "    total_val_tokens = 0\n",
    "    total_val_correct_emotions = 0\n",
    "    total_val_correct_causes = 0\n",
    "    total_val_predictions = 0\n",
    "    true_labels_emotion = []\n",
    "    predicted_labels_emotion = []\n",
    "    true_labels_cause = []\n",
    "    predicted_labels_cause = []\n",
    "    padded_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in tqdm(validation_dataloader):\n",
    "            audio = val_batch['audio'].to('cuda')\n",
    "            video = val_batch['video'].to('cuda')\n",
    "            text = val_batch['text'].to('cuda')\n",
    "            emotion_indices = val_batch['emotion_labels'].to('cuda')\n",
    "            cause_indices = val_batch['cause_labels'].to('cuda')\n",
    "            pad_mask = val_batch['pad_mask'].to('cuda')\n",
    "            \n",
    "            audio_copy = audio.clone().detach()\n",
    "            video_copy = video.clone().detach()\n",
    "            text_copy = text.clone().detach()\n",
    "\n",
    "            emotion_logits = emotion_model(audio_copy, video_copy, text_copy)\n",
    "\n",
    "            # Reshape emotion_logits\n",
    "            emotion_logits = emotion_logits.view(-1, emotion_logits.size(-1))\n",
    "\n",
    "            # Flatten emotion_indices (assuming it's a 2D tensor with shape [batch_size, max_sequence_length])\n",
    "            emotion_indices = emotion_indices.view(-1)\n",
    "\n",
    "            pad_mask = pad_mask.view(-1)   \n",
    "\n",
    "            # Calculate the loss, excluding padded positions\n",
    "            val_loss = emotion_criterion(emotion_logits, emotion_indices)\n",
    "            masked_loss = val_loss #torch.sum(val_loss * pad_mask) / torch.sum(pad_mask)\n",
    "            \n",
    "            cause_logits = cause_model(audio, video, text)\n",
    "            cause_logits = cause_logits.view(-1, cause_logits.size(-1))\n",
    "            cause_indices = cause_indices.view(-1)\n",
    "            cause_loss = cause_criterion(cause_logits, cause_indices)\n",
    "            masked_loss += cause_loss\n",
    "            \n",
    "            total_val_loss += masked_loss.item()\n",
    "            total_val_tokens += torch.sum(pad_mask).item()\n",
    "            \n",
    "            predicted_emotions_val = torch.argmax(emotion_logits, dim=1)\n",
    "            correct_predictions_val = ((predicted_emotions_val == emotion_indices) * pad_mask).sum().item()\n",
    "            total_val_correct_emotions += correct_predictions_val\n",
    "            \n",
    "            predicted_causes_val = torch.argmax(cause_logits, dim=1)\n",
    "            correct_predictions_causes_val = ((predicted_causes_val == cause_indices) * pad_mask).sum().item()\n",
    "            total_val_correct_causes += correct_predictions_causes_val\n",
    "            \n",
    "            total_val_predictions += torch.sum(pad_mask).item()\n",
    "\n",
    "            # Store true and predicted labels for F1 score calculation\n",
    "            true_labels_emotion.extend(emotion_indices.cpu().numpy())\n",
    "            predicted_labels_emotion.extend(predicted_emotions_val.cpu().numpy())\n",
    "            \n",
    "            true_labels_cause.extend(cause_indices.cpu().numpy())\n",
    "            predicted_labels_cause.extend(predicted_causes_val.cpu().numpy())\n",
    "            padded_labels.extend(pad_mask.cpu().numpy())\n",
    "\n",
    "    final_true_labels_emotion = [label for label, pad in zip(true_labels_emotion, padded_labels) if pad == 1]\n",
    "    final_predicted_labels_emotion = [label for label, pad in zip(predicted_labels_emotion, padded_labels) if pad == 1]\n",
    "    \n",
    "    final_true_labels_cause = [label for label, pad in zip(true_labels_cause, padded_labels) if pad == 1]\n",
    "    final_predicted_labels_cause = [label for label, pad in zip(predicted_labels_cause, padded_labels) if pad == 1]\n",
    "    \n",
    "    emotion_classification_rep = classification_report(final_true_labels_emotion, final_predicted_labels_emotion)\n",
    "    cause_classification_rep = classification_report(final_true_labels_cause, final_predicted_labels_cause)\n",
    "    \n",
    "    # Calculate and print the average loss for this epoch\n",
    "    avg_loss = total_loss / total_tokens\n",
    "    avg_val_loss = total_val_loss / total_val_tokens\n",
    "    \n",
    "    print(\"===============================\")\n",
    "    print(\"Training data metrics\")\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Training Loss: {avg_loss}\")\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Accuracy: {total_correct_emotions / total_predictions}\")\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Accuracy: {total_correct_causes / total_predictions}\")\n",
    "    \n",
    "    print(\"VALIDATION METRICS\")\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Validation Loss: {avg_val_loss}\")\n",
    "    print(emotion_classification_rep)\n",
    "    print(cause_classification_rep)\n",
    "    print(\"===============================\")\n",
    "\n",
    "    torch.save(emotion_model.state_dict(), f\"/tmp/semeval24_task3/final_models/emotion_models/emotion_model_{epoch:02}.pt\")\n",
    "    torch.save(cause_model.state_dict(), f\"/tmp/semeval24_task3/final_models/cause_models/cause_model_{epoch:02}.pt\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
