{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "066d5d04-2185-416e-aaf0-8846772be663",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/tmp/akshett.jindal\"\n",
    "DATA_DIR = \"/tmp/semeval24_task3\"\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24957026-04db-4ee1-a068-f597462b1d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/home2/suyash.mathur/audios/train/dia1utt1.wav',\n",
       "  '/home2/suyash.mathur/audios/train/dia1utt2.wav',\n",
       "  '/home2/suyash.mathur/audios/train/dia1utt3.wav',\n",
       "  '/home2/suyash.mathur/audios/train/dia1utt4.wav',\n",
       "  '/home2/suyash.mathur/audios/train/dia1utt5.wav'],\n",
       " 19920)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "audio_files_glob = \"/home2/suyash.mathur/audios/*/*.wav\"\n",
    "# path.join(\n",
    "#     DATA_DIR,\n",
    "#     \"train\",\n",
    "#     \"SemEval-2024_Task3\",\n",
    "#     \"Evaluation_Data\",\n",
    "#     \"audios\",\n",
    "#     \"*.wav\",\n",
    "# )\n",
    "\n",
    "wav_files = sorted(\n",
    "    glob(audio_files_glob, recursive=True),\n",
    "    key=lambda fname: tuple([int(num) for num in re.findall(r\"\\d+\", fname)]),\n",
    ")\n",
    "wav_files[:5], len(wav_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4a20914-866c-433c-8616-23b9072319a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "MODEL_ID = \"facebook/wav2vec2-large-960h\"\n",
    "CONFIG_CLASS = transformers.AutoConfig\n",
    "MODEL_CLASS = transformers.AutoModel\n",
    "PROCESSOR_CLASS = transformers.AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5292332-9f66-4045-9217-e1963009b6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = MODEL_ID.replace(\"/\", \"_\").replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1dee3d9-68fe-48ca-b1bd-1d4caabbb6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "HUGGINGFACE_CACHE_DIR = path.join(BASE_DIR, \".huggingface_cache\")\n",
    "OUTPUT_FILE = path.join(DATA_DIR, \"audio_embeddings\", f\"audio_embeddings_{MODEL_NAME}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58fb640f-4db2-470c-87ba-ce00303a481f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device = torch.device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aed960ec-f2d1-43aa-8ad6-adefc9785590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessor_config.json: 100%|██████████| 159/159 [00:00<00:00, 46.1kB/s]\n",
      "config.json: 100%|██████████| 843/843 [00:00<00:00, 2.21MB/s]\n"
     ]
    }
   ],
   "source": [
    "processor = PROCESSOR_CLASS.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    cache_dir=HUGGINGFACE_CACHE_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb174f87-4f30-4efc-97d8-546a2a21bc07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 1.26G/1.26G [00:24<00:00, 50.6MB/s]\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = MODEL_CLASS.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    cache_dir=HUGGINGFACE_CACHE_DIR,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6033c9c-8ccf-4803-9be1-a27fdd88425a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'audio'],\n",
       "    num_rows: 19920\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import numpy\n",
    "from os import path\n",
    "import soundfile\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def data_generator():\n",
    "    for wav_file in tqdm(wav_files):\n",
    "        with open(wav_file, \"rb\") as f:\n",
    "            audio_data, _ = soundfile.read(f)\n",
    "        audio_id = path.basename(wav_file).replace(\".wav\", \"\")\n",
    "        yield { \"id\": audio_id, \"audio\": numpy.average(audio_data, axis=1) }\n",
    "\n",
    "dataset = Dataset.from_generator(data_generator, cache_dir=path.join(HUGGINGFACE_CACHE_DIR, \"datasets\"))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66f5c61e-abfc-45c5-8cb8-4df5123c5779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx+n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7900c68a-f273-490e-86ba-57d2fa25a47d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path\n",
    "import pickle\n",
    "\n",
    "if path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"rb\") as f:\n",
    "        OUTPUTS = pickle.load(f)\n",
    "else:\n",
    "    OUTPUTS = {}\n",
    "\n",
    "list(OUTPUTS.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ece134a8-3f96-4c87-b01c-bb1abda8990d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19920 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 19745/19920 [20:17<00:10, 17.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed on d['id']= ['dia2020utt6']: Calculated padded input size per channel: (1). Kernel size: (2). Kernel size can't be greater than actual input size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19920/19920 [20:26<00:00, 16.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy\n",
    "from os import path\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for batch_num, d in tqdm(enumerate(batch(dataset, n=BATCH_SIZE)), total=len(dataset) // BATCH_SIZE):\n",
    "\n",
    "        if all(audio_id in OUTPUTS for audio_id in d[\"id\"]):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            inputs = processor(\n",
    "                raw_speech=d[\"audio\"],\n",
    "                padding=BATCH_SIZE > 1,\n",
    "                sampling_rate=16000,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            for k in inputs.keys():\n",
    "                inputs[k] = inputs[k].to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            for k in outputs.keys():\n",
    "                outputs[k] = numpy.array(outputs[k].cpu())\n",
    "\n",
    "            last_hidden_states = numpy.mean(outputs[\"last_hidden_state\"], axis=1)\n",
    "\n",
    "            for audio_id, hs in zip(d[\"id\"], last_hidden_states):\n",
    "                OUTPUTS[audio_id] = last_hidden_states\n",
    "\n",
    "        except Exception as ex:\n",
    "            print(f\"Failed on {d['id']= }: {ex}\")\n",
    "\n",
    "with open(OUTPUT_FILE, \"wb\") as f:\n",
    "    pickle.dump(OUTPUTS, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d346e51-198c-41b9-8434-27e502df9847",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a49f7bf8-19eb-45cc-951e-e53263e889c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"/tmp/akshett.jindal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86cf564d-82b0-4406-9a7d-ead12c52f51c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "batch_files_glob = path.join(\n",
    "    BASE_DIR,\n",
    "    \"shared_task\",\n",
    "    \"task03\",\n",
    "    \"audio_embeddings\",\n",
    "    \"microsoft_wavlm-base-sd\",\n",
    "    \"batch_*.pkl\",\n",
    ")\n",
    "\n",
    "batch_files = sorted(\n",
    "    glob(batch_files_glob, recursive=True),\n",
    "    key=lambda fname: tuple([int(num) for num in re.findall(r\"\\d+\", fname)]),\n",
    ")\n",
    "batch_files[:5], len(batch_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfd02c7f-60d0-4a29-b348-3119688267da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "for batch_file in batch_files:\n",
    "    with open(batch_file, \"rb\") as f:\n",
    "        batches = pickle.load(f)\n",
    "    for batch in batches:\n",
    "        for audio_id, hidden_state in zip(batch[\"ids\"], batch[\"last_hidden_state\"]):\n",
    "            embeddings[audio_id] = hidden_state\n",
    "\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac90ef5e-d542-4ff8-b455-b3a25ae9f700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(embeddings.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b652126-9f51-4ad8-bc38-d42dc7a54a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/akshett.jindal/shared_task/task03/audio_embeddings/microsoft_wavlm-base-sd_last_layer_embeddings.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home2/suyash.mathur/semeval24/task3/wavlm/wavlm_embeddings.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsuyash-gnode/home2/suyash.mathur/semeval24/task3/wavlm/wavlm_embeddings.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsuyash-gnode/home2/suyash.mathur/semeval24/task3/wavlm/wavlm_embeddings.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsuyash-gnode/home2/suyash.mathur/semeval24/task3/wavlm/wavlm_embeddings.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(BASE_DIR, \u001b[39m\"\u001b[39;49m\u001b[39mshared_task\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtask03\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39maudio_embeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmicrosoft_wavlm-base-sd_last_layer_embeddings.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsuyash-gnode/home2/suyash.mathur/semeval24/task3/wavlm/wavlm_embeddings.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(embeddings, f)\n",
      "File \u001b[0;32m~/anaconda3/envs/mindeye/lib/python3.10/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/akshett.jindal/shared_task/task03/audio_embeddings/microsoft_wavlm-base-sd_last_layer_embeddings.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os.path\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"shared_task\", \"task03\", \"audio_embeddings\", \"microsoft_wavlm-base-sd_last_layer_embeddings.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
